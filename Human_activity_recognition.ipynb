{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activities are the class labels\n",
    "# It is a 6 class classification\n",
    "ACTIVITIES = {\n",
    "    0: 'WALKING',\n",
    "    1: 'WALKING_UPSTAIRS',\n",
    "    2: 'WALKING_DOWNSTAIRS',\n",
    "    3: 'SITTING',\n",
    "    4: 'STANDING',\n",
    "    5: 'LAYING',\n",
    "}\n",
    "\n",
    "# Utility function to print the confusion matrix\n",
    "def confusion_matrix(Y_true, Y_pred):\n",
    "    Y_true = pd.Series([ACTIVITIES[y] for y in np.argmax(Y_true, axis=1)])\n",
    "    Y_pred = pd.Series([ACTIVITIES[y] for y in np.argmax(Y_pred, axis=1)])\n",
    "\n",
    "    return pd.crosstab(Y_true, Y_pred, rownames=['True'], colnames=['Pred'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data directory\n",
    "DATADIR = 'UCI_HAR_Dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Raw data signals\n",
    "# Signals are from Accelerometer and Gyroscope\n",
    "# The signals are in x,y,z directions\n",
    "# Sensor signals are filtered to have only body acceleration\n",
    "# excluding the acceleration due to gravity\n",
    "# Triaxial acceleration from the accelerometer is total acceleration\n",
    "SIGNALS = [\n",
    "    \"body_acc_x\",\n",
    "    \"body_acc_y\",\n",
    "    \"body_acc_z\",\n",
    "    \"body_gyro_x\",\n",
    "    \"body_gyro_y\",\n",
    "    \"body_gyro_z\",\n",
    "    \"total_acc_x\",\n",
    "    \"total_acc_y\",\n",
    "    \"total_acc_z\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function to read the data from csv file\n",
    "def _read_csv(filename):\n",
    "    return pd.read_csv(filename, delim_whitespace=True, header=None)\n",
    "\n",
    "# Utility function to load the load\n",
    "def load_signals(subset):\n",
    "    signals_data = []\n",
    "\n",
    "    for signal in SIGNALS:\n",
    "        filename = f'UCI_HAR_Dataset/{subset}/Inertial Signals/{signal}_{subset}.txt'\n",
    "        signals_data.append(\n",
    "            _read_csv(filename).as_matrix()\n",
    "        ) \n",
    "\n",
    "    # Transpose is used to change the dimensionality of the output,\n",
    "    # aggregating the signals by combination of sample/timestep.\n",
    "    # Resultant shape is (7352 train/2947 test samples, 128 timesteps, 9 signals)\n",
    "    return np.transpose(signals_data, (1, 2, 0))\n",
    "\n",
    "def load_y(subset):\n",
    "    \"\"\"\n",
    "    The objective that we are trying to predict is a integer, from 1 to 6,\n",
    "    that represents a human activity. We return a binary representation of \n",
    "    every sample objective as a 6 bits vector using One Hot Encoding\n",
    "    (https://pandas.pydata.org/pandas-docs/stable/generated/pandas.get_dummies.html)\n",
    "    \"\"\"\n",
    "    filename = f'UCI_HAR_Dataset/{subset}/y_{subset}.txt'\n",
    "    y = _read_csv(filename)[0]\n",
    "\n",
    "    return pd.get_dummies(y).as_matrix()\n",
    "def load_data():\n",
    "    \"\"\"\n",
    "    Obtain the dataset from multiple files.\n",
    "    Returns: X_train, X_test, y_train, y_test\n",
    "    \"\"\"\n",
    "    X_train, X_test = load_signals('train'), load_signals('test')\n",
    "    y_train, y_test = load_y('train'), load_y('test')\n",
    "\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing tensorflow\n",
    "np.random.seed(42)\n",
    "import tensorflow as tf\n",
    "tf.set_random_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuring a session\n",
    "session_conf = tf.ConfigProto(\n",
    "    intra_op_parallelism_threads=1,\n",
    "    inter_op_parallelism_threads=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Import Keras\n",
    "from keras import backend as K\n",
    "sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers.core import Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Initializing parameters\n",
    "epochs = 30\n",
    "batch_size = 16\n",
    "n_hidden = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function to count the number of classes\n",
    "def _count_classes(y):\n",
    "    return len(set([tuple(category) for category in y]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\patha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:12: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X train shape : (7352, 128, 9)\n",
      "X test shape : (2947, 128, 9)\n",
      "Y train shape : (7352, 6)\n",
      "Y train shape : (2947, 6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\patha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:30: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n"
     ]
    }
   ],
   "source": [
    "# Loading the train and test data\n",
    "X_train, X_test, Y_train, Y_test = load_data()\n",
    "print(\"X train shape :\",X_train.shape)\n",
    "print(\"X test shape :\",X_test.shape)\n",
    "print(\"Y train shape :\",Y_train.shape)\n",
    "print(\"Y train shape :\",Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128\n",
      "9\n",
      "7352\n"
     ]
    }
   ],
   "source": [
    "timesteps = len(X_train[0])\n",
    "input_dim = len(X_train[0][0])\n",
    "n_classes = _count_classes(Y_train)\n",
    "\n",
    "print(timesteps)\n",
    "print(input_dim)\n",
    "print(len(X_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Defining the Architecture of LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_3 (LSTM)                (None, 32)                5376      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 6)                 198       \n",
      "=================================================================\n",
      "Total params: 5,574\n",
      "Trainable params: 5,574\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Initiliazing the sequential model\n",
    "model = Sequential()\n",
    "# Configuring the parameters\n",
    "model.add(LSTM(n_hidden, input_shape=(timesteps, input_dim)))\n",
    "# Adding a dropout layer\n",
    "model.add(Dropout(0.5))\n",
    "# Adding a dense output layer with sigmoid activation\n",
    "model.add(Dense(n_classes, activation='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compiling the model\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/30\n",
      "7352/7352 [==============================] - 92s 13ms/step - loss: 1.3018 - acc: 0.4395 - val_loss: 1.1254 - val_acc: 0.4662\n",
      "Epoch 2/30\n",
      "7352/7352 [==============================] - 94s 13ms/step - loss: 0.9666 - acc: 0.5880 - val_loss: 0.9491 - val_acc: 0.5714\n",
      "Epoch 3/30\n",
      "7352/7352 [==============================] - 97s 13ms/step - loss: 0.7812 - acc: 0.6408 - val_loss: 0.8286 - val_acc: 0.5850\n",
      "Epoch 4/30\n",
      "7352/7352 [==============================] - 95s 13ms/step - loss: 0.6941 - acc: 0.6574 - val_loss: 0.7297 - val_acc: 0.6128\n",
      "Epoch 5/30\n",
      "7352/7352 [==============================] - 92s 13ms/step - loss: 0.6336 - acc: 0.6912 - val_loss: 0.7359 - val_acc: 0.6787\n",
      "Epoch 6/30\n",
      "7352/7352 [==============================] - 94s 13ms/step - loss: 0.5859 - acc: 0.7134 - val_loss: 0.7015 - val_acc: 0.6939\n",
      "Epoch 7/30\n",
      "7352/7352 [==============================] - 95s 13ms/step - loss: 0.5692 - acc: 0.7477 - val_loss: 0.5995 - val_acc: 0.7387\n",
      "Epoch 8/30\n",
      "7352/7352 [==============================] - 96s 13ms/step - loss: 0.4899 - acc: 0.7809 - val_loss: 0.5762 - val_acc: 0.7387\n",
      "Epoch 9/30\n",
      "7352/7352 [==============================] - 90s 12ms/step - loss: 0.4482 - acc: 0.7886 - val_loss: 0.7413 - val_acc: 0.7126\n",
      "Epoch 10/30\n",
      "7352/7352 [==============================] - 90s 12ms/step - loss: 0.4132 - acc: 0.8077 - val_loss: 0.5048 - val_acc: 0.7513\n",
      "Epoch 11/30\n",
      "7352/7352 [==============================] - 89s 12ms/step - loss: 0.3985 - acc: 0.8274 - val_loss: 0.5234 - val_acc: 0.7452\n",
      "Epoch 12/30\n",
      "7352/7352 [==============================] - 91s 12ms/step - loss: 0.3378 - acc: 0.8638 - val_loss: 0.4114 - val_acc: 0.8833\n",
      "Epoch 13/30\n",
      "7352/7352 [==============================] - 91s 12ms/step - loss: 0.2947 - acc: 0.9051 - val_loss: 0.4386 - val_acc: 0.8731\n",
      "Epoch 14/30\n",
      "7352/7352 [==============================] - 90s 12ms/step - loss: 0.2448 - acc: 0.9291 - val_loss: 0.3768 - val_acc: 0.8921\n",
      "Epoch 15/30\n",
      "7352/7352 [==============================] - 91s 12ms/step - loss: 0.2157 - acc: 0.9331 - val_loss: 0.4441 - val_acc: 0.8931\n",
      "Epoch 16/30\n",
      "7352/7352 [==============================] - 90s 12ms/step - loss: 0.2053 - acc: 0.9366 - val_loss: 0.4162 - val_acc: 0.8968\n",
      "Epoch 17/30\n",
      "7352/7352 [==============================] - 89s 12ms/step - loss: 0.2028 - acc: 0.9404 - val_loss: 0.4538 - val_acc: 0.8962\n",
      "Epoch 18/30\n",
      "7352/7352 [==============================] - 93s 13ms/step - loss: 0.1911 - acc: 0.9419 - val_loss: 0.3964 - val_acc: 0.8999\n",
      "Epoch 19/30\n",
      "7352/7352 [==============================] - 96s 13ms/step - loss: 0.1912 - acc: 0.9407 - val_loss: 0.3165 - val_acc: 0.9030\n",
      "Epoch 20/30\n",
      "7352/7352 [==============================] - 96s 13ms/step - loss: 0.1732 - acc: 0.9446 - val_loss: 0.4546 - val_acc: 0.8904\n",
      "Epoch 21/30\n",
      "7352/7352 [==============================] - 94s 13ms/step - loss: 0.1782 - acc: 0.9444 - val_loss: 0.3346 - val_acc: 0.9063\n",
      "Epoch 22/30\n",
      "7352/7352 [==============================] - 95s 13ms/step - loss: 0.1812 - acc: 0.9418 - val_loss: 0.8164 - val_acc: 0.8582\n",
      "Epoch 23/30\n",
      "7352/7352 [==============================] - 95s 13ms/step - loss: 0.1824 - acc: 0.9426 - val_loss: 0.4240 - val_acc: 0.9036\n",
      "Epoch 24/30\n",
      "7352/7352 [==============================] - 94s 13ms/step - loss: 0.1726 - acc: 0.9429 - val_loss: 0.4067 - val_acc: 0.9148\n",
      "Epoch 25/30\n",
      "7352/7352 [==============================] - 96s 13ms/step - loss: 0.1737 - acc: 0.9411 - val_loss: 0.3396 - val_acc: 0.9074\n",
      "Epoch 26/30\n",
      "7352/7352 [==============================] - 96s 13ms/step - loss: 0.1650 - acc: 0.9461 - val_loss: 0.3806 - val_acc: 0.9019\n",
      "Epoch 27/30\n",
      "7352/7352 [==============================] - 89s 12ms/step - loss: 0.1925 - acc: 0.9415 - val_loss: 0.6464 - val_acc: 0.8850\n",
      "Epoch 28/30\n",
      "7352/7352 [==============================] - 91s 12ms/step - loss: 0.1965 - acc: 0.9425 - val_loss: 0.3363 - val_acc: 0.9203\n",
      "Epoch 29/30\n",
      "7352/7352 [==============================] - 92s 12ms/step - loss: 0.1889 - acc: 0.9431 - val_loss: 0.3737 - val_acc: 0.9158\n",
      "Epoch 30/30\n",
      "7352/7352 [==============================] - 95s 13ms/step - loss: 0.1945 - acc: 0.9414 - val_loss: 0.3088 - val_acc: 0.9097\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x29b5ee36a20>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the model\n",
    "model.fit(X_train,\n",
    "          Y_train,\n",
    "          batch_size=batch_size,\n",
    "          validation_data=(X_test, Y_test),\n",
    "          epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred                LAYING  SITTING  STANDING  WALKING  WALKING_DOWNSTAIRS  \\\n",
      "True                                                                         \n",
      "LAYING                 512        0        25        0                   0   \n",
      "SITTING                  3      410        75        0                   0   \n",
      "STANDING                 0       87       445        0                   0   \n",
      "WALKING                  0        0         0      481                   2   \n",
      "WALKING_DOWNSTAIRS       0        0         0        0                 382   \n",
      "WALKING_UPSTAIRS         0        0         0        2                  18   \n",
      "\n",
      "Pred                WALKING_UPSTAIRS  \n",
      "True                                  \n",
      "LAYING                             0  \n",
      "SITTING                            3  \n",
      "STANDING                           0  \n",
      "WALKING                           13  \n",
      "WALKING_DOWNSTAIRS                38  \n",
      "WALKING_UPSTAIRS                 451  \n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "print(confusion_matrix(Y_test, model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2947/2947 [==============================] - 4s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.3087582236972612, 0.9097387173396675]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- With a simple 2 layer architecture we got 90.09% accuracy and a loss of 0.30\n",
    "- We can further imporve the performace with Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2 LSTM Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM,Dense,Dropout,Activation,BatchNormalization,Conv2D,Flatten,TimeDistributed,Conv1D\n",
    "from keras.regularizers import *\n",
    "from keras.callbacks import LearningRateScheduler,TerminateOnNaN,EarlyStopping\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.initializers import VarianceScaling\n",
    "from keras.optimizers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def lr_decay(epoch):\n",
    "    return float(0.0001 * math.pow(0.6, math.floor((1+epoch)/10)))\n",
    "lr = LearningRateScheduler(lr_decay)\n",
    "tm = TerminateOnNaN()\n",
    "es = EarlyStopping(monitor = 'accuracy')\n",
    "init = VarianceScaling(scale = 1.0,mode = 'fan_avg',distribution = 'normal')\n",
    "adam = Adam(lr=0.001)\n",
    "rmsprop = RMSprop(lr = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_24 (LSTM)               (None, 128, 32)           5376      \n",
      "_________________________________________________________________\n",
      "batch_normalization_22 (Batc (None, 128, 32)           128       \n",
      "_________________________________________________________________\n",
      "dropout_22 (Dropout)         (None, 128, 32)           0         \n",
      "_________________________________________________________________\n",
      "lstm_25 (LSTM)               (None, 32)                8320      \n",
      "_________________________________________________________________\n",
      "batch_normalization_23 (Batc (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "dropout_23 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 6)                 198       \n",
      "=================================================================\n",
      "Total params: 14,150\n",
      "Trainable params: 14,022\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(32,activation = 'relu',return_sequences=True, input_shape=(timesteps, input_dim),recurrent_initializer=\"glorot_uniform\",recurrent_regularizer=l2(0.003) ))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.6))\n",
    "model.add(LSTM(32,recurrent_initializer=\"glorot_uniform\",recurrent_regularizer=l2(0.003)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(6, activation='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 31.9 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "          optimizer=adam,\n",
    "          metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/30\n",
      "7352/7352 [==============================] - 67s 9ms/step - loss: 1.3829 - accuracy: 0.5645 - val_loss: 1.1387 - val_accuracy: 0.5826\n",
      "Epoch 2/30\n",
      "7352/7352 [==============================] - 70s 10ms/step - loss: 0.9055 - accuracy: 0.6557 - val_loss: 0.8158 - val_accuracy: 0.5864\n",
      "Epoch 3/30\n",
      "7352/7352 [==============================] - 69s 9ms/step - loss: 0.7707 - accuracy: 0.6740 - val_loss: 0.8092 - val_accuracy: 0.6583\n",
      "Epoch 4/30\n",
      "7352/7352 [==============================] - 68s 9ms/step - loss: 0.6547 - accuracy: 0.7334 - val_loss: 1.1115 - val_accuracy: 0.6464\n",
      "Epoch 5/30\n",
      "7352/7352 [==============================] - 67s 9ms/step - loss: 0.4773 - accuracy: 0.8672 - val_loss: 1.3450 - val_accuracy: 0.6844\n",
      "Epoch 6/30\n",
      "7352/7352 [==============================] - 63s 9ms/step - loss: 0.3395 - accuracy: 0.9142 - val_loss: 2.3442 - val_accuracy: 0.5894\n",
      "Epoch 7/30\n",
      "7352/7352 [==============================] - 63s 9ms/step - loss: 0.2963 - accuracy: 0.9221 - val_loss: 1.2052 - val_accuracy: 0.7109\n",
      "Epoch 8/30\n",
      "7352/7352 [==============================] - 65s 9ms/step - loss: 0.2843 - accuracy: 0.9259 - val_loss: 0.8428 - val_accuracy: 0.7859\n",
      "Epoch 9/30\n",
      "7352/7352 [==============================] - 64s 9ms/step - loss: 0.2381 - accuracy: 0.9399 - val_loss: 0.9233 - val_accuracy: 0.7896\n",
      "Epoch 10/30\n",
      "7352/7352 [==============================] - 63s 9ms/step - loss: 0.2241 - accuracy: 0.9385 - val_loss: 0.8582 - val_accuracy: 0.8168\n",
      "Epoch 11/30\n",
      "7352/7352 [==============================] - 63s 9ms/step - loss: 0.2098 - accuracy: 0.9436 - val_loss: 1.4082 - val_accuracy: 0.7631\n",
      "Epoch 12/30\n",
      "7352/7352 [==============================] - 63s 9ms/step - loss: 0.2018 - accuracy: 0.9446 - val_loss: 0.9004 - val_accuracy: 0.8154\n",
      "Epoch 13/30\n",
      "7352/7352 [==============================] - 65s 9ms/step - loss: 0.2038 - accuracy: 0.9403 - val_loss: 1.3356 - val_accuracy: 0.7730\n",
      "Epoch 14/30\n",
      "7352/7352 [==============================] - 64s 9ms/step - loss: 0.2054 - accuracy: 0.9415 - val_loss: 1.2279 - val_accuracy: 0.7560\n",
      "Epoch 15/30\n",
      "7352/7352 [==============================] - 69s 9ms/step - loss: 0.2251 - accuracy: 0.9373 - val_loss: 0.7518 - val_accuracy: 0.8242\n",
      "Epoch 16/30\n",
      "7352/7352 [==============================] - 65s 9ms/step - loss: 0.2005 - accuracy: 0.9382 - val_loss: 0.6747 - val_accuracy: 0.8578\n",
      "Epoch 17/30\n",
      "7352/7352 [==============================] - 64s 9ms/step - loss: 0.1937 - accuracy: 0.9467 - val_loss: 0.4177 - val_accuracy: 0.8904\n",
      "Epoch 18/30\n",
      "7352/7352 [==============================] - 65s 9ms/step - loss: 0.1917 - accuracy: 0.9397 - val_loss: 0.4571 - val_accuracy: 0.9043\n",
      "Epoch 19/30\n",
      "7352/7352 [==============================] - 64s 9ms/step - loss: 0.1866 - accuracy: 0.9441 - val_loss: 0.3585 - val_accuracy: 0.9104\n",
      "Epoch 20/30\n",
      "7352/7352 [==============================] - 64s 9ms/step - loss: 0.1792 - accuracy: 0.9460 - val_loss: 0.3843 - val_accuracy: 0.9084\n",
      "Epoch 21/30\n",
      "7352/7352 [==============================] - 66s 9ms/step - loss: 0.1835 - accuracy: 0.9482 - val_loss: 0.3312 - val_accuracy: 0.9128\n",
      "Epoch 22/30\n",
      "7352/7352 [==============================] - 64s 9ms/step - loss: 0.1753 - accuracy: 0.9465 - val_loss: 0.3680 - val_accuracy: 0.9121\n",
      "Epoch 23/30\n",
      "7352/7352 [==============================] - 63s 9ms/step - loss: 0.1657 - accuracy: 0.9484 - val_loss: 0.4147 - val_accuracy: 0.9070\n",
      "Epoch 24/30\n",
      "7352/7352 [==============================] - 64s 9ms/step - loss: 0.1698 - accuracy: 0.9479 - val_loss: 0.3551 - val_accuracy: 0.9087\n",
      "Epoch 25/30\n",
      "7352/7352 [==============================] - 65s 9ms/step - loss: 0.1683 - accuracy: 0.9510 - val_loss: 0.3739 - val_accuracy: 0.9114\n",
      "Epoch 26/30\n",
      "7352/7352 [==============================] - 63s 9ms/step - loss: 0.1646 - accuracy: 0.9517 - val_loss: 0.3635 - val_accuracy: 0.9070\n",
      "Epoch 27/30\n",
      "7352/7352 [==============================] - 64s 9ms/step - loss: 0.1615 - accuracy: 0.9506 - val_loss: 0.4292 - val_accuracy: 0.9040\n",
      "Epoch 28/30\n",
      "7352/7352 [==============================] - 63s 9ms/step - loss: 0.1548 - accuracy: 0.9516 - val_loss: 0.4087 - val_accuracy: 0.9108\n",
      "Epoch 29/30\n",
      "7352/7352 [==============================] - 66s 9ms/step - loss: 0.1549 - accuracy: 0.9491 - val_loss: 0.4016 - val_accuracy: 0.9135\n",
      "Epoch 30/30\n",
      "7352/7352 [==============================] - 63s 9ms/step - loss: 0.1513 - accuracy: 0.9508 - val_loss: 0.3972 - val_accuracy: 0.9179\n",
      "Wall time: 32min 29s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Training the model\n",
    "result = model.fit(X_train,\n",
    "          Y_train,\n",
    "          batch_size=32,\n",
    "          validation_data=(X_test, Y_test),callbacks=[lr,tm],\n",
    "          epochs=30,verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2947/2947 [==============================] - 11s 4ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3971564822520872, 0.9178826212882996]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred                LAYING  SITTING  STANDING  WALKING  WALKING_DOWNSTAIRS  \\\n",
      "True                                                                         \n",
      "LAYING                 537        0         0        0                   0   \n",
      "SITTING                  0      408        78        0                   0   \n",
      "STANDING                 0       91       441        0                   0   \n",
      "WALKING                  0        0         0      462                  33   \n",
      "WALKING_DOWNSTAIRS       0        0         0        1                 418   \n",
      "WALKING_UPSTAIRS         0        0         1        8                  23   \n",
      "\n",
      "Pred                WALKING_UPSTAIRS  \n",
      "True                                  \n",
      "LAYING                             0  \n",
      "SITTING                            5  \n",
      "STANDING                           0  \n",
      "WALKING                            1  \n",
      "WALKING_DOWNSTAIRS                 1  \n",
      "WALKING_UPSTAIRS                 439  \n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "print(confusion_matrix(Y_test, model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 LSTM Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_26 (LSTM)               (None, 128, 16)           1664      \n",
      "_________________________________________________________________\n",
      "batch_normalization_24 (Batc (None, 128, 16)           64        \n",
      "_________________________________________________________________\n",
      "dropout_24 (Dropout)         (None, 128, 16)           0         \n",
      "_________________________________________________________________\n",
      "lstm_27 (LSTM)               (None, 128, 16)           2112      \n",
      "_________________________________________________________________\n",
      "batch_normalization_25 (Batc (None, 128, 16)           64        \n",
      "_________________________________________________________________\n",
      "dropout_25 (Dropout)         (None, 128, 16)           0         \n",
      "_________________________________________________________________\n",
      "lstm_28 (LSTM)               (None, 16)                2112      \n",
      "_________________________________________________________________\n",
      "batch_normalization_26 (Batc (None, 16)                64        \n",
      "_________________________________________________________________\n",
      "dropout_26 (Dropout)         (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 6)                 102       \n",
      "=================================================================\n",
      "Total params: 6,182\n",
      "Trainable params: 6,086\n",
      "Non-trainable params: 96\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(16,activation = 'relu',return_sequences=True, input_shape=(timesteps, input_dim),recurrent_initializer=\"glorot_uniform\",recurrent_regularizer=l2(0.003) ))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.6))\n",
    "model.add(LSTM(16,return_sequences=True,recurrent_initializer=\"glorot_uniform\",recurrent_regularizer=l2(0.003)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.4))\n",
    "model.add(LSTM(16,recurrent_initializer=\"glorot_uniform\",recurrent_regularizer=l2(0.003)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(6, activation='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 46.9 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "          optimizer=adam,\n",
    "          metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/30\n",
      "7352/7352 [==============================] - 96s 13ms/step - loss: 1.0784 - accuracy: 0.6155 - val_loss: 2.4525 - val_accuracy: 0.2104\n",
      "Epoch 2/30\n",
      "7352/7352 [==============================] - 93s 13ms/step - loss: 0.8143 - accuracy: 0.6495 - val_loss: 1.8998 - val_accuracy: 0.3624\n",
      "Epoch 3/30\n",
      "7352/7352 [==============================] - 93s 13ms/step - loss: 0.7552 - accuracy: 0.6600 - val_loss: 0.7603 - val_accuracy: 0.6135\n",
      "Epoch 4/30\n",
      "7352/7352 [==============================] - 94s 13ms/step - loss: 0.7052 - accuracy: 0.6668 - val_loss: 0.8918 - val_accuracy: 0.5836\n",
      "Epoch 5/30\n",
      "7352/7352 [==============================] - 93s 13ms/step - loss: 0.6817 - accuracy: 0.6634 - val_loss: 0.8573 - val_accuracy: 0.5813\n",
      "Epoch 6/30\n",
      "7352/7352 [==============================] - 93s 13ms/step - loss: 0.6373 - accuracy: 0.6685 - val_loss: 2.4977 - val_accuracy: 0.3264\n",
      "Epoch 7/30\n",
      "7352/7352 [==============================] - 94s 13ms/step - loss: 0.5997 - accuracy: 0.6759 - val_loss: 2.8237 - val_accuracy: 0.3444\n",
      "Epoch 8/30\n",
      "7352/7352 [==============================] - 94s 13ms/step - loss: 0.6100 - accuracy: 0.6861 - val_loss: 2.2098 - val_accuracy: 0.3963\n",
      "Epoch 9/30\n",
      "7352/7352 [==============================] - 93s 13ms/step - loss: 0.5890 - accuracy: 0.6989 - val_loss: 1.3614 - val_accuracy: 0.6179\n",
      "Epoch 10/30\n",
      "7352/7352 [==============================] - 93s 13ms/step - loss: 0.5710 - accuracy: 0.7180 - val_loss: 1.0003 - val_accuracy: 0.6437\n",
      "Epoch 11/30\n",
      "7352/7352 [==============================] - 93s 13ms/step - loss: 0.5547 - accuracy: 0.7539 - val_loss: 2.3520 - val_accuracy: 0.4041\n",
      "Epoch 12/30\n",
      "7352/7352 [==============================] - 93s 13ms/step - loss: 0.5145 - accuracy: 0.7893 - val_loss: 1.3954 - val_accuracy: 0.5490\n",
      "Epoch 13/30\n",
      "7352/7352 [==============================] - 93s 13ms/step - loss: 0.4829 - accuracy: 0.7888 - val_loss: 2.1027 - val_accuracy: 0.4744\n",
      "Epoch 14/30\n",
      "7352/7352 [==============================] - 93s 13ms/step - loss: 0.4618 - accuracy: 0.7983 - val_loss: 0.9134 - val_accuracy: 0.6634\n",
      "Epoch 15/30\n",
      "7352/7352 [==============================] - 93s 13ms/step - loss: 0.4855 - accuracy: 0.7892 - val_loss: 1.2600 - val_accuracy: 0.5959\n",
      "Epoch 16/30\n",
      "7352/7352 [==============================] - 94s 13ms/step - loss: 0.4586 - accuracy: 0.8142 - val_loss: 0.8715 - val_accuracy: 0.7292\n",
      "Epoch 17/30\n",
      "7352/7352 [==============================] - 94s 13ms/step - loss: 0.4255 - accuracy: 0.8254 - val_loss: 0.9037 - val_accuracy: 0.7557\n",
      "Epoch 18/30\n",
      "7352/7352 [==============================] - 96s 13ms/step - loss: 0.4076 - accuracy: 0.8424 - val_loss: 0.7246 - val_accuracy: 0.7682\n",
      "Epoch 19/30\n",
      "7352/7352 [==============================] - 94s 13ms/step - loss: 0.3881 - accuracy: 0.8630 - val_loss: 1.1181 - val_accuracy: 0.7526\n",
      "Epoch 20/30\n",
      "7352/7352 [==============================] - 94s 13ms/step - loss: 0.3557 - accuracy: 0.8886 - val_loss: 0.7369 - val_accuracy: 0.8147\n",
      "Epoch 21/30\n",
      "7352/7352 [==============================] - 94s 13ms/step - loss: 0.3532 - accuracy: 0.8912 - val_loss: 0.6189 - val_accuracy: 0.8239\n",
      "Epoch 22/30\n",
      "7352/7352 [==============================] - 94s 13ms/step - loss: 0.3318 - accuracy: 0.9025 - val_loss: 0.6092 - val_accuracy: 0.8317\n",
      "Epoch 23/30\n",
      "7352/7352 [==============================] - 94s 13ms/step - loss: 0.3031 - accuracy: 0.9101 - val_loss: 0.5088 - val_accuracy: 0.8738\n",
      "Epoch 24/30\n",
      "7352/7352 [==============================] - 94s 13ms/step - loss: 0.2878 - accuracy: 0.9146 - val_loss: 0.4594 - val_accuracy: 0.8633\n",
      "Epoch 25/30\n",
      "7352/7352 [==============================] - 93s 13ms/step - loss: 0.2818 - accuracy: 0.9151 - val_loss: 0.3919 - val_accuracy: 0.8853\n",
      "Epoch 26/30\n",
      "7352/7352 [==============================] - 94s 13ms/step - loss: 0.2665 - accuracy: 0.9222 - val_loss: 0.3856 - val_accuracy: 0.8907\n",
      "Epoch 27/30\n",
      "7352/7352 [==============================] - 94s 13ms/step - loss: 0.2552 - accuracy: 0.9267 - val_loss: 0.4395 - val_accuracy: 0.8758\n",
      "Epoch 28/30\n",
      "7352/7352 [==============================] - 93s 13ms/step - loss: 0.2483 - accuracy: 0.9283 - val_loss: 0.4254 - val_accuracy: 0.9040\n",
      "Epoch 29/30\n",
      "7352/7352 [==============================] - 94s 13ms/step - loss: 0.2474 - accuracy: 0.9257 - val_loss: 0.4692 - val_accuracy: 0.9023\n",
      "Epoch 30/30\n",
      "7352/7352 [==============================] - 94s 13ms/step - loss: 0.2402 - accuracy: 0.9300 - val_loss: 0.4864 - val_accuracy: 0.8951\n",
      "Wall time: 46min 55s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Training the model\n",
    "result = model.fit(X_train,\n",
    "          Y_train,\n",
    "          batch_size=32,\n",
    "          validation_data=(X_test, Y_test),callbacks=[lr,tm],\n",
    "          epochs=30,verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2947/2947 [==============================] - 15s 5ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.48638685676640564, 0.8951476216316223]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred                LAYING  SITTING  STANDING  WALKING  WALKING_DOWNSTAIRS  \\\n",
      "True                                                                         \n",
      "LAYING                 510        0         0        0                   0   \n",
      "SITTING                  5      415        64        1                   0   \n",
      "STANDING                 0      104       427        0                   0   \n",
      "WALKING                  0        0         0      493                   1   \n",
      "WALKING_DOWNSTAIRS       0        0         0       54                 366   \n",
      "WALKING_UPSTAIRS         0        2         0       31                  11   \n",
      "\n",
      "Pred                WALKING_UPSTAIRS  \n",
      "True                                  \n",
      "LAYING                            27  \n",
      "SITTING                            6  \n",
      "STANDING                           1  \n",
      "WALKING                            2  \n",
      "WALKING_DOWNSTAIRS                 0  \n",
      "WALKING_UPSTAIRS                 427  \n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "print(confusion_matrix(Y_test, model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_41\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_36 (LSTM)               (None, 128, 100)          44000     \n",
      "_________________________________________________________________\n",
      "batch_normalization_69 (Batc (None, 128, 100)          400       \n",
      "_________________________________________________________________\n",
      "dropout_130 (Dropout)        (None, 128, 100)          0         \n",
      "_________________________________________________________________\n",
      "lstm_37 (LSTM)               (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "batch_normalization_70 (Batc (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "dropout_131 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_70 (Dense)             (None, 6)                 606       \n",
      "=================================================================\n",
      "Total params: 125,806\n",
      "Trainable params: 125,406\n",
      "Non-trainable params: 400\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(100,activation = 'relu',return_sequences=True, input_shape=(timesteps, input_dim),recurrent_initializer=\"glorot_uniform\",recurrent_regularizer=l2(0.003) ))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.8))\n",
    "model.add(LSTM(100,recurrent_initializer=\"glorot_uniform\",recurrent_regularizer=l2(0.0003)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.8))\n",
    "# model.add(LSTM(28,return_sequences=True,recurrent_initializer=\"glorot_uniform\",recurrent_regularizer=l2(0.0003)))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Dropout(0.8))\n",
    "# # model.add(LSTM(64,return_sequences=True,recurrent_initializer=\"glorot_uniform\",recurrent_regularizer=l2(0.003)))\n",
    "# # model.add(BatchNormalization())\n",
    "# # model.add(Dropout(0.6))\n",
    "# model.add(LSTM(16,recurrent_initializer=\"glorot_uniform\",recurrent_regularizer=l2(0.0003)))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Dropout(0.8))\n",
    "model.add(Dense(n_classes, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 47.9 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "          optimizer=adam,\n",
    "          metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/50\n",
      "7352/7352 [==============================] - 71s 10ms/step - loss: 1.9772 - accuracy: 0.5590 - val_loss: 1.1925 - val_accuracy: 0.6155\n",
      "Epoch 2/50\n",
      "7352/7352 [==============================] - 63s 9ms/step - loss: 1.3167 - accuracy: 0.6606 - val_loss: 1.1295 - val_accuracy: 0.6603\n",
      "Epoch 3/50\n",
      "7352/7352 [==============================] - 64s 9ms/step - loss: 1.1459 - accuracy: 0.6821 - val_loss: 1.0407 - val_accuracy: 0.7380\n",
      "Epoch 4/50\n",
      "7352/7352 [==============================] - 66s 9ms/step - loss: 1.0348 - accuracy: 0.7121 - val_loss: 0.9470 - val_accuracy: 0.7513\n",
      "Epoch 5/50\n",
      "7352/7352 [==============================] - 69s 9ms/step - loss: 0.9272 - accuracy: 0.7422 - val_loss: 0.9104 - val_accuracy: 0.7638\n",
      "Epoch 6/50\n",
      "7352/7352 [==============================] - 65s 9ms/step - loss: 0.8319 - accuracy: 0.7705 - val_loss: 0.9305 - val_accuracy: 0.7760\n",
      "Epoch 7/50\n",
      "7352/7352 [==============================] - 63s 9ms/step - loss: 0.7345 - accuracy: 0.8040 - val_loss: 0.8735 - val_accuracy: 0.8029\n",
      "Epoch 8/50\n",
      "7352/7352 [==============================] - 65s 9ms/step - loss: 0.6537 - accuracy: 0.8298 - val_loss: 0.8620 - val_accuracy: 0.8174\n",
      "Epoch 9/50\n",
      "7352/7352 [==============================] - 65s 9ms/step - loss: 0.5461 - accuracy: 0.8700 - val_loss: 0.8959 - val_accuracy: 0.8144\n",
      "Epoch 10/50\n",
      "7352/7352 [==============================] - 68s 9ms/step - loss: 0.5148 - accuracy: 0.8886 - val_loss: 0.7962 - val_accuracy: 0.8439\n",
      "Epoch 11/50\n",
      "7352/7352 [==============================] - 66s 9ms/step - loss: 0.4713 - accuracy: 0.8976 - val_loss: 0.7703 - val_accuracy: 0.8585\n",
      "Epoch 12/50\n",
      "7352/7352 [==============================] - 66s 9ms/step - loss: 0.4485 - accuracy: 0.9038 - val_loss: 0.7946 - val_accuracy: 0.8585\n",
      "Epoch 13/50\n",
      "7352/7352 [==============================] - 69s 9ms/step - loss: 0.4188 - accuracy: 0.9138 - val_loss: 0.7353 - val_accuracy: 0.8680\n",
      "Epoch 14/50\n",
      "7352/7352 [==============================] - 68s 9ms/step - loss: 0.4218 - accuracy: 0.9128 - val_loss: 0.6979 - val_accuracy: 0.8744\n",
      "Epoch 15/50\n",
      "7352/7352 [==============================] - 73s 10ms/step - loss: 0.4035 - accuracy: 0.9193 - val_loss: 0.7285 - val_accuracy: 0.8697\n",
      "Epoch 16/50\n",
      "7352/7352 [==============================] - 69s 9ms/step - loss: 0.3860 - accuracy: 0.9229 - val_loss: 0.7551 - val_accuracy: 0.8687\n",
      "Epoch 17/50\n",
      "7352/7352 [==============================] - 75s 10ms/step - loss: 0.3784 - accuracy: 0.9232 - val_loss: 0.6416 - val_accuracy: 0.8839\n",
      "Epoch 18/50\n",
      "7352/7352 [==============================] - 90s 12ms/step - loss: 0.3696 - accuracy: 0.9286 - val_loss: 0.7278 - val_accuracy: 0.8755\n",
      "Epoch 19/50\n",
      "7352/7352 [==============================] - 86s 12ms/step - loss: 0.3651 - accuracy: 0.9278 - val_loss: 0.7883 - val_accuracy: 0.8673\n",
      "Epoch 20/50\n",
      "7352/7352 [==============================] - 78s 11ms/step - loss: 0.3522 - accuracy: 0.9336 - val_loss: 0.7850 - val_accuracy: 0.8666\n",
      "Epoch 21/50\n",
      "7352/7352 [==============================] - 72s 10ms/step - loss: 0.3471 - accuracy: 0.9331 - val_loss: 0.6614 - val_accuracy: 0.8914\n",
      "Epoch 22/50\n",
      "7352/7352 [==============================] - 66s 9ms/step - loss: 0.3451 - accuracy: 0.9332 - val_loss: 0.7449 - val_accuracy: 0.8724\n",
      "Epoch 23/50\n",
      "7352/7352 [==============================] - 66s 9ms/step - loss: 0.3378 - accuracy: 0.9346 - val_loss: 0.7535 - val_accuracy: 0.8789\n",
      "Epoch 24/50\n",
      "7352/7352 [==============================] - 66s 9ms/step - loss: 0.3488 - accuracy: 0.9342 - val_loss: 0.6762 - val_accuracy: 0.8839\n",
      "Epoch 25/50\n",
      "7352/7352 [==============================] - 74s 10ms/step - loss: 0.3296 - accuracy: 0.9396 - val_loss: 0.6535 - val_accuracy: 0.8877\n",
      "Epoch 26/50\n",
      "7352/7352 [==============================] - 71s 10ms/step - loss: 0.3326 - accuracy: 0.9332 - val_loss: 0.6109 - val_accuracy: 0.8948\n",
      "Epoch 27/50\n",
      "7352/7352 [==============================] - 70s 10ms/step - loss: 0.3321 - accuracy: 0.9355 - val_loss: 0.6816 - val_accuracy: 0.8863\n",
      "Epoch 28/50\n",
      "7352/7352 [==============================] - 66s 9ms/step - loss: 0.3348 - accuracy: 0.9351 - val_loss: 0.7173 - val_accuracy: 0.8867\n",
      "Epoch 29/50\n",
      "7352/7352 [==============================] - 68s 9ms/step - loss: 0.3132 - accuracy: 0.9400 - val_loss: 0.6871 - val_accuracy: 0.8826\n",
      "Epoch 30/50\n",
      "3936/7352 [===============>..............] - ETA: 26s - loss: 0.3062 - accuracy: 0.9433"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1239\u001b[1;33m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[0;32m   1240\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[0;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 196\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3290\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3291\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[1;32m-> 3292\u001b[1;33m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[0;32m   3293\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3294\u001b[0m     output_structure = nest.pack_sequence_as(\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[0;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1458\u001b[1;33m                                                run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1459\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Training the model\n",
    "result = model.fit(X_train,\n",
    "          Y_train,\n",
    "          batch_size=32,\n",
    "          validation_data=(X_test, Y_test),callbacks=[lr,tm],\n",
    "          epochs=50,verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM,Dense,Dropout,Activation,BatchNormalization,Conv2D,Flatten,TimeDistributed,Conv1D,MaxPool1D\n",
    "from keras.regularizers import *\n",
    "from keras.callbacks import LearningRateScheduler,TerminateOnNaN\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.initializers import VarianceScaling\n",
    "from keras.optimizers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def lr_decay(epoch):\n",
    "    return float(0.001 * math.pow(0.6, math.floor((1+epoch)/10)))\n",
    "lr = LearningRateScheduler(lr_decay)\n",
    "tm = TerminateOnNaN()\n",
    "init = VarianceScaling(scale = 1.0,mode = 'fan_avg',distribution = 'normal')\n",
    "adam = Adam(lr=0.001)\n",
    "rmsprop = RMSprop(lr = 0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 1 CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1020 15:47:24.126830  3136 nn_ops.py:4224] Large dropout rate: 0.7 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "W1020 15:47:24.139796  3136 deprecation_wrapper.py:119] From C:\\Users\\patha\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_10 (Conv1D)           (None, 126, 128)          3584      \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 126, 128)          512       \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 126, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 63, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_11 (Conv1D)           (None, 61, 32)            12320     \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 61, 32)            128       \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 61, 32)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 30, 32)            0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 960)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 64)                61504     \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 6)                 390       \n",
      "=================================================================\n",
      "Total params: 78,438\n",
      "Trainable params: 78,118\n",
      "Non-trainable params: 320\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1 = Sequential()\n",
    "model1.add(Conv1D(128,kernel_size=3,kernel_initializer='he_normal',input_shape=(timesteps, input_dim),kernel_regularizer = l2(0.003),activation ='relu'))\n",
    "model1.add(BatchNormalization())\n",
    "model1.add(Dropout(0.7))\n",
    "model1.add(MaxPool1D(2))\n",
    "# model1.add(Conv1D(64,kernel_size=3,kernel_initializer='he_normal',kernel_regularizer = l2(0.003),activation ='relu'))\n",
    "# model1.add(BatchNormalization())\n",
    "# model1.add(Dropout(0.5))\n",
    "model1.add(Conv1D(32,kernel_size=3,kernel_initializer='he_normal',kernel_regularizer = l2(0.003),activation ='relu'))\n",
    "model1.add(BatchNormalization())\n",
    "model1.add(Dropout(0.5))\n",
    "model1.add(MaxPool1D(2))\n",
    "model1.add(Flatten())\n",
    "model1.add(Dense(64,activation = 'relu'))\n",
    "model1.add(Dropout(0.5))\n",
    "model1.add(Dense(n_classes,activation = 'softmax'))\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 62 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model1.compile(loss='categorical_crossentropy',\n",
    "          optimizer=adam,\n",
    "          metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/30\n",
      "7352/7352 [==============================] - 4s 515us/step - loss: 1.9771 - accuracy: 0.5979 - val_loss: 4.9397 - val_accuracy: 0.3207\n",
      "Epoch 2/30\n",
      "7352/7352 [==============================] - 3s 380us/step - loss: 1.4026 - accuracy: 0.7314 - val_loss: 4.1904 - val_accuracy: 0.4869\n",
      "Epoch 3/30\n",
      "7352/7352 [==============================] - 3s 366us/step - loss: 1.1415 - accuracy: 0.8052 - val_loss: 2.9938 - val_accuracy: 0.5724\n",
      "Epoch 4/30\n",
      "7352/7352 [==============================] - 3s 368us/step - loss: 0.9091 - accuracy: 0.8596 - val_loss: 2.8087 - val_accuracy: 0.5935\n",
      "Epoch 5/30\n",
      "7352/7352 [==============================] - 3s 370us/step - loss: 0.7309 - accuracy: 0.8988 - val_loss: 2.2223 - val_accuracy: 0.6464\n",
      "Epoch 6/30\n",
      "7352/7352 [==============================] - 3s 369us/step - loss: 0.6076 - accuracy: 0.9199 - val_loss: 2.1633 - val_accuracy: 0.6793\n",
      "Epoch 7/30\n",
      "7352/7352 [==============================] - 3s 373us/step - loss: 0.5299 - accuracy: 0.9230 - val_loss: 1.5285 - val_accuracy: 0.7343\n",
      "Epoch 8/30\n",
      "7352/7352 [==============================] - 3s 373us/step - loss: 0.4898 - accuracy: 0.9259 - val_loss: 1.4341 - val_accuracy: 0.7642\n",
      "Epoch 9/30\n",
      "7352/7352 [==============================] - 3s 372us/step - loss: 0.4336 - accuracy: 0.9336 - val_loss: 0.8901 - val_accuracy: 0.8205\n",
      "Epoch 10/30\n",
      "7352/7352 [==============================] - 3s 365us/step - loss: 0.3782 - accuracy: 0.9389 - val_loss: 0.8177 - val_accuracy: 0.8398\n",
      "Epoch 11/30\n",
      "7352/7352 [==============================] - 3s 371us/step - loss: 0.3632 - accuracy: 0.9416 - val_loss: 0.8873 - val_accuracy: 0.8157\n",
      "Epoch 12/30\n",
      "7352/7352 [==============================] - 3s 369us/step - loss: 0.3385 - accuracy: 0.9430 - val_loss: 0.6890 - val_accuracy: 0.8599\n",
      "Epoch 13/30\n",
      "7352/7352 [==============================] - 3s 371us/step - loss: 0.3313 - accuracy: 0.9388 - val_loss: 0.6125 - val_accuracy: 0.8785\n",
      "Epoch 14/30\n",
      "7352/7352 [==============================] - 3s 368us/step - loss: 0.3046 - accuracy: 0.9457 - val_loss: 0.6476 - val_accuracy: 0.8575\n",
      "Epoch 15/30\n",
      "7352/7352 [==============================] - 3s 367us/step - loss: 0.2992 - accuracy: 0.9421 - val_loss: 0.9274 - val_accuracy: 0.8130\n",
      "Epoch 16/30\n",
      "7352/7352 [==============================] - 3s 367us/step - loss: 0.2819 - accuracy: 0.9452 - val_loss: 0.7748 - val_accuracy: 0.8283\n",
      "Epoch 17/30\n",
      "7352/7352 [==============================] - 3s 368us/step - loss: 0.2619 - accuracy: 0.9470 - val_loss: 0.9110 - val_accuracy: 0.8283\n",
      "Epoch 18/30\n",
      "7352/7352 [==============================] - 3s 368us/step - loss: 0.2538 - accuracy: 0.9497 - val_loss: 0.6998 - val_accuracy: 0.8415\n",
      "Epoch 19/30\n",
      "7352/7352 [==============================] - 3s 367us/step - loss: 0.2658 - accuracy: 0.9452 - val_loss: 0.7977 - val_accuracy: 0.8178\n",
      "Epoch 20/30\n",
      "7352/7352 [==============================] - 3s 366us/step - loss: 0.2549 - accuracy: 0.9434 - val_loss: 0.4292 - val_accuracy: 0.9023\n",
      "Epoch 21/30\n",
      "7352/7352 [==============================] - 3s 372us/step - loss: 0.2363 - accuracy: 0.9489 - val_loss: 0.5025 - val_accuracy: 0.8748\n",
      "Epoch 22/30\n",
      "7352/7352 [==============================] - 3s 368us/step - loss: 0.2292 - accuracy: 0.9479 - val_loss: 0.4710 - val_accuracy: 0.8829\n",
      "Epoch 23/30\n",
      "7352/7352 [==============================] - 3s 365us/step - loss: 0.2217 - accuracy: 0.9513 - val_loss: 0.4679 - val_accuracy: 0.8826\n",
      "Epoch 24/30\n",
      "7352/7352 [==============================] - 3s 376us/step - loss: 0.2199 - accuracy: 0.9484 - val_loss: 0.4759 - val_accuracy: 0.8785\n",
      "Epoch 25/30\n",
      "7352/7352 [==============================] - 3s 383us/step - loss: 0.2177 - accuracy: 0.9509 - val_loss: 0.4614 - val_accuracy: 0.8856\n",
      "Epoch 26/30\n",
      "7352/7352 [==============================] - 3s 375us/step - loss: 0.2132 - accuracy: 0.9505 - val_loss: 0.4465 - val_accuracy: 0.9033\n",
      "Epoch 27/30\n",
      "7352/7352 [==============================] - 3s 367us/step - loss: 0.2138 - accuracy: 0.9482 - val_loss: 0.6949 - val_accuracy: 0.8317\n",
      "Epoch 28/30\n",
      "7352/7352 [==============================] - 3s 368us/step - loss: 0.2121 - accuracy: 0.9478 - val_loss: 0.5558 - val_accuracy: 0.8724\n",
      "Epoch 29/30\n",
      "7352/7352 [==============================] - 3s 372us/step - loss: 0.2019 - accuracy: 0.9529 - val_loss: 0.4052 - val_accuracy: 0.9080\n",
      "Epoch 30/30\n",
      "7352/7352 [==============================] - 3s 363us/step - loss: 0.1954 - accuracy: 0.9524 - val_loss: 0.4131 - val_accuracy: 0.9016\n",
      "Wall time: 1min 24s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Training the model\n",
    "result = model1.fit(X_train,\n",
    "          Y_train,\n",
    "          batch_size=32,\n",
    "          validation_data=(X_test, Y_test),callbacks=[lr,tm],\n",
    "          epochs=30,verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2947/2947 [==============================] - 0s 149us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4131184876278614, 0.9015948176383972]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.evaluate(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred                LAYING  SITTING  STANDING  WALKING  WALKING_DOWNSTAIRS  \\\n",
      "True                                                                         \n",
      "LAYING                 537        0         0        0                   0   \n",
      "SITTING                  0      326       164        0                   0   \n",
      "STANDING                 0       44       488        0                   0   \n",
      "WALKING                  0       11        14      449                   0   \n",
      "WALKING_DOWNSTAIRS       0        0         8        1                 401   \n",
      "WALKING_UPSTAIRS         0        7         0        0                   8   \n",
      "\n",
      "Pred                WALKING_UPSTAIRS  \n",
      "True                                  \n",
      "LAYING                             0  \n",
      "SITTING                            1  \n",
      "STANDING                           0  \n",
      "WALKING                           22  \n",
      "WALKING_DOWNSTAIRS                10  \n",
      "WALKING_UPSTAIRS                 456  \n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "print(confusion_matrix(Y_test, model1.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model2 CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_22 (Conv1D)           (None, 122, 128)          8192      \n",
      "_________________________________________________________________\n",
      "batch_normalization_22 (Batc (None, 122, 128)          512       \n",
      "_________________________________________________________________\n",
      "dropout_31 (Dropout)         (None, 122, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_12 (MaxPooling (None, 61, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_23 (Conv1D)           (None, 55, 64)            57408     \n",
      "_________________________________________________________________\n",
      "batch_normalization_23 (Batc (None, 55, 64)            256       \n",
      "_________________________________________________________________\n",
      "dropout_32 (Dropout)         (None, 55, 64)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_13 (MaxPooling (None, 27, 64)            0         \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 1728)              0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 32)                55328     \n",
      "_________________________________________________________________\n",
      "dropout_33 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 6)                 198       \n",
      "=================================================================\n",
      "Total params: 121,894\n",
      "Trainable params: 121,510\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2 = Sequential()\n",
    "model2.add(Conv1D(128,kernel_size=7,kernel_initializer='he_normal',input_shape=(timesteps, input_dim),kernel_regularizer = l2(0.003),activation ='relu'))\n",
    "model2.add(BatchNormalization())\n",
    "model2.add(Dropout(0.7))\n",
    "model2.add(MaxPool1D(2))\n",
    "# model2.add(Conv1D(64,kernel_size=3,kernel_initializer='he_normal',kernel_regularizer = l2(0.003),activation ='relu'))\n",
    "# model2.add(BatchNormalization())\n",
    "# model2.add(Dropout(0.5))\n",
    "model2.add(Conv1D(64,kernel_size=7,kernel_initializer='he_normal',kernel_regularizer = l2(0.003),activation ='relu'))\n",
    "model2.add(BatchNormalization())\n",
    "model2.add(Dropout(0.7))\n",
    "model2.add(MaxPool1D(2))\n",
    "model2.add(Flatten())\n",
    "model2.add(Dense(32,activation = 'relu'))\n",
    "model2.add(Dropout(0.5))\n",
    "model2.add(Dense(n_classes,activation = 'softmax'))\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 40.9 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model2.compile(loss='categorical_crossentropy',\n",
    "          optimizer=adam,\n",
    "          metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/30\n",
      "7352/7352 [==============================] - 3s 435us/step - loss: 2.0337 - accuracy: 0.5975 - val_loss: 8.0444 - val_accuracy: 0.3563\n",
      "Epoch 2/30\n",
      "7352/7352 [==============================] - 2s 257us/step - loss: 1.4303 - accuracy: 0.6749 - val_loss: 11.8737 - val_accuracy: 0.3539\n",
      "Epoch 3/30\n",
      "7352/7352 [==============================] - 2s 255us/step - loss: 1.1435 - accuracy: 0.7125 - val_loss: 11.7078 - val_accuracy: 0.3841\n",
      "Epoch 4/30\n",
      "7352/7352 [==============================] - 2s 256us/step - loss: 0.8885 - accuracy: 0.7900 - val_loss: 7.3924 - val_accuracy: 0.4835\n",
      "Epoch 5/30\n",
      "7352/7352 [==============================] - 2s 267us/step - loss: 0.6426 - accuracy: 0.8788 - val_loss: 5.6671 - val_accuracy: 0.5317\n",
      "Epoch 6/30\n",
      "7352/7352 [==============================] - 2s 260us/step - loss: 0.5403 - accuracy: 0.8962 - val_loss: 3.0467 - val_accuracy: 0.6603\n",
      "Epoch 7/30\n",
      "7352/7352 [==============================] - 2s 256us/step - loss: 0.4829 - accuracy: 0.9082 - val_loss: 1.8925 - val_accuracy: 0.7523\n",
      "Epoch 8/30\n",
      "7352/7352 [==============================] - 2s 263us/step - loss: 0.4188 - accuracy: 0.9200 - val_loss: 0.6114 - val_accuracy: 0.8568\n",
      "Epoch 9/30\n",
      "7352/7352 [==============================] - 2s 259us/step - loss: 0.4317 - accuracy: 0.9149 - val_loss: 1.2068 - val_accuracy: 0.8134\n",
      "Epoch 10/30\n",
      "7352/7352 [==============================] - 2s 264us/step - loss: 0.3913 - accuracy: 0.9240 - val_loss: 1.7844 - val_accuracy: 0.7445\n",
      "Epoch 11/30\n",
      "7352/7352 [==============================] - 2s 258us/step - loss: 0.3487 - accuracy: 0.9279 - val_loss: 1.3529 - val_accuracy: 0.7940\n",
      "Epoch 12/30\n",
      "7352/7352 [==============================] - 2s 265us/step - loss: 0.3250 - accuracy: 0.9313 - val_loss: 1.0702 - val_accuracy: 0.8107\n",
      "Epoch 13/30\n",
      "7352/7352 [==============================] - 2s 262us/step - loss: 0.3079 - accuracy: 0.9302 - val_loss: 1.2088 - val_accuracy: 0.7954\n",
      "Epoch 14/30\n",
      "7352/7352 [==============================] - 2s 285us/step - loss: 0.3085 - accuracy: 0.9316 - val_loss: 1.6542 - val_accuracy: 0.7984\n",
      "Epoch 15/30\n",
      "7352/7352 [==============================] - 2s 265us/step - loss: 0.3101 - accuracy: 0.9237 - val_loss: 1.4639 - val_accuracy: 0.8127\n",
      "Epoch 16/30\n",
      "7352/7352 [==============================] - 2s 258us/step - loss: 0.2747 - accuracy: 0.9350 - val_loss: 0.9176 - val_accuracy: 0.8344\n",
      "Epoch 17/30\n",
      "7352/7352 [==============================] - 2s 257us/step - loss: 0.2771 - accuracy: 0.9302 - val_loss: 0.6340 - val_accuracy: 0.8626\n",
      "Epoch 18/30\n",
      "7352/7352 [==============================] - 2s 256us/step - loss: 0.2627 - accuracy: 0.9346 - val_loss: 0.8502 - val_accuracy: 0.8561\n",
      "Epoch 19/30\n",
      "7352/7352 [==============================] - 2s 254us/step - loss: 0.2568 - accuracy: 0.9302 - val_loss: 1.8618 - val_accuracy: 0.7774\n",
      "Epoch 20/30\n",
      "7352/7352 [==============================] - 2s 264us/step - loss: 0.2482 - accuracy: 0.9336 - val_loss: 1.9363 - val_accuracy: 0.7543\n",
      "Epoch 21/30\n",
      "7352/7352 [==============================] - 2s 256us/step - loss: 0.2496 - accuracy: 0.9342 - val_loss: 1.2623 - val_accuracy: 0.7971\n",
      "Epoch 22/30\n",
      "7352/7352 [==============================] - 2s 256us/step - loss: 0.2323 - accuracy: 0.9358 - val_loss: 0.9469 - val_accuracy: 0.8117\n",
      "Epoch 23/30\n",
      "7352/7352 [==============================] - 2s 255us/step - loss: 0.2262 - accuracy: 0.9377 - val_loss: 1.3494 - val_accuracy: 0.7889\n",
      "Epoch 24/30\n",
      "7352/7352 [==============================] - 2s 265us/step - loss: 0.2301 - accuracy: 0.9328 - val_loss: 1.3258 - val_accuracy: 0.8018\n",
      "Epoch 25/30\n",
      "7352/7352 [==============================] - 2s 258us/step - loss: 0.2264 - accuracy: 0.9359 - val_loss: 1.3989 - val_accuracy: 0.7978\n",
      "Epoch 26/30\n",
      "7352/7352 [==============================] - 2s 256us/step - loss: 0.2154 - accuracy: 0.9397 - val_loss: 0.4875 - val_accuracy: 0.8955\n",
      "Epoch 27/30\n",
      "7352/7352 [==============================] - 2s 256us/step - loss: 0.2139 - accuracy: 0.9334 - val_loss: 0.8968 - val_accuracy: 0.8266\n",
      "Epoch 28/30\n",
      "7352/7352 [==============================] - 2s 260us/step - loss: 0.2171 - accuracy: 0.9361 - val_loss: 1.1524 - val_accuracy: 0.7961\n",
      "Epoch 29/30\n",
      "7352/7352 [==============================] - 2s 253us/step - loss: 0.2147 - accuracy: 0.9350 - val_loss: 0.5527 - val_accuracy: 0.8816\n",
      "Epoch 30/30\n",
      "7352/7352 [==============================] - 2s 257us/step - loss: 0.2093 - accuracy: 0.9381 - val_loss: 0.6932 - val_accuracy: 0.8561\n",
      "Wall time: 1min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Training the model\n",
    "result = model2.fit(X_train,\n",
    "          Y_train,\n",
    "          batch_size=64,\n",
    "          validation_data=(X_test, Y_test),callbacks=[lr,tm],\n",
    "          epochs=30,verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2947/2947 [==============================] - 1s 171us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6932297824882919, 0.8561248779296875]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.evaluate(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred                LAYING  SITTING  STANDING  WALKING  WALKING_DOWNSTAIRS  \\\n",
      "True                                                                         \n",
      "LAYING                 537        0         0        0                   0   \n",
      "SITTING                  5      321       164        0                   0   \n",
      "STANDING                 0       25       507        0                   0   \n",
      "WALKING                  0        0        80      416                   0   \n",
      "WALKING_DOWNSTAIRS       0       10         7       13                 385   \n",
      "WALKING_UPSTAIRS         0       65        27        4                  18   \n",
      "\n",
      "Pred                WALKING_UPSTAIRS  \n",
      "True                                  \n",
      "LAYING                             0  \n",
      "SITTING                            1  \n",
      "STANDING                           0  \n",
      "WALKING                            0  \n",
      "WALKING_DOWNSTAIRS                 5  \n",
      "WALKING_UPSTAIRS                 357  \n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "print(confusion_matrix(Y_test, model2.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using Divide and Conquer Based Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function to read the data from csv file\n",
    "def _read_csv(filename):\n",
    "    return pd.read_csv(filename, delim_whitespace=True, header=None)\n",
    "\n",
    "# Utility function to load the load\n",
    "def load_signals(subset):\n",
    "    signals_data = []\n",
    "\n",
    "    for signal in SIGNALS:\n",
    "        filename = f'UCI_HAR_Dataset/{subset}/Inertial Signals/{signal}_{subset}.txt'\n",
    "        signals_data.append(\n",
    "            _read_csv(filename).as_matrix()\n",
    "        ) \n",
    "\n",
    "    # Transpose is used to change the dimensionality of the output,\n",
    "    # aggregating the signals by combination of sample/timestep.\n",
    "    # Resultant shape is (7352 train/2947 test samples, 128 timesteps, 9 signals)\n",
    "    return np.transpose(signals_data, (1, 2, 0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_y_bi(subset):\n",
    "    \"\"\"\n",
    "    The objective that we are trying to predict is a integer, from 1 to 6,\n",
    "    that represents a human activity. We return a binary representation of \n",
    "    every sample objective as a 6 bits vector using One Hot Encoding\n",
    "    (https://pandas.pydata.org/pandas-docs/stable/generated/pandas.get_dummies.html)\n",
    "    \"\"\"\n",
    "    filename = f'UCI_HAR_Dataset/{subset}/y_{subset}.txt'\n",
    "    y = _read_csv(filename)[0]\n",
    "    y[y<=3] = 0\n",
    "    y[y>3] = 1\n",
    "    return pd.get_dummies(y).as_matrix()\n",
    "\n",
    "def load_data_bi():\n",
    "    \"\"\"\n",
    "    Obtain the dataset from multiple files.\n",
    "    Returns: X_train, X_test, y_train, y_test\n",
    "    \"\"\"\n",
    "    X_train, X_test = load_signals('train'), load_signals('test')\n",
    "    y_train,y_test = load_y_bi('train'),load_y_bi(\"test\")\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\patha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:12: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "X_train_bi,X_test_bi,Y_train_bi,Y_test_bi  = load_data_bi()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1023 16:24:53.602773  7024 nn_ops.py:4224] Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "W1023 16:24:53.637979  7024 deprecation_wrapper.py:119] From C:\\Users\\patha\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 126, 32)           896       \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 124, 32)           3104      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 124, 32)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 62, 32)            0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1984)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                127040    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 131,170\n",
      "Trainable params: 131,170\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_bi= Sequential()\n",
    "model_bi.add(Conv1D(32,kernel_size=3,kernel_initializer='he_normal',input_shape=(timesteps, input_dim),kernel_regularizer = l2(0.003),activation ='relu'))\n",
    "#model_bi.add(BatchNormalization())\n",
    "#model_bi.add(MaxPool1D(2))\n",
    "model_bi.add(Conv1D(32,kernel_size=3,kernel_initializer='he_normal',kernel_regularizer = l2(0.003),activation ='relu'))\n",
    "#model_bi.add(BatchNormalization())\n",
    "model_bi.add(Dropout(0.6))\n",
    "model_bi.add(MaxPool1D(2))\n",
    "model_bi.add(Flatten())\n",
    "model_bi.add(Dense(64,activation = 'relu'))\n",
    "# model_bi.add(Dropout(0.5))\n",
    "model_bi.add(Dense(2,activation = 'softmax'))\n",
    "model_bi.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 165 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model_bi.compile(loss='categorical_crossentropy',\n",
    "          optimizer=adam,\n",
    "          metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1023 16:25:01.943298  7024 deprecation_wrapper.py:119] From C:\\Users\\patha\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/30\n",
      "7352/7352 [==============================] - 8s 1ms/step - loss: 0.3814 - accuracy: 0.9814 - val_loss: 0.3111 - val_accuracy: 0.9891\n",
      "Epoch 2/30\n",
      "7352/7352 [==============================] - 2s 291us/step - loss: 0.2390 - accuracy: 0.9992 - val_loss: 0.2380 - val_accuracy: 0.9810\n",
      "Epoch 3/30\n",
      "7352/7352 [==============================] - 2s 278us/step - loss: 0.1721 - accuracy: 0.9986 - val_loss: 0.2054 - val_accuracy: 0.9779\n",
      "Epoch 4/30\n",
      "7352/7352 [==============================] - 2s 280us/step - loss: 0.1266 - accuracy: 0.9995 - val_loss: 0.1782 - val_accuracy: 0.9756\n",
      "Epoch 5/30\n",
      "7352/7352 [==============================] - 2s 285us/step - loss: 0.0982 - accuracy: 0.9990 - val_loss: 0.1229 - val_accuracy: 0.9844\n",
      "Epoch 6/30\n",
      "7352/7352 [==============================] - 2s 294us/step - loss: 0.0754 - accuracy: 0.9996 - val_loss: 0.0871 - val_accuracy: 0.9891\n",
      "Epoch 7/30\n",
      "7352/7352 [==============================] - 2s 274us/step - loss: 0.0598 - accuracy: 0.9999 - val_loss: 0.0805 - val_accuracy: 0.9908\n",
      "Epoch 8/30\n",
      "7352/7352 [==============================] - 2s 296us/step - loss: 0.0528 - accuracy: 0.9985 - val_loss: 0.0607 - val_accuracy: 0.9922\n",
      "Epoch 9/30\n",
      "7352/7352 [==============================] - 2s 297us/step - loss: 0.0424 - accuracy: 0.9997 - val_loss: 0.0520 - val_accuracy: 0.9936\n",
      "Epoch 10/30\n",
      "7352/7352 [==============================] - 2s 288us/step - loss: 0.0360 - accuracy: 1.0000 - val_loss: 0.0464 - val_accuracy: 0.9956\n",
      "Epoch 11/30\n",
      "7352/7352 [==============================] - 2s 287us/step - loss: 0.0320 - accuracy: 1.0000 - val_loss: 0.0519 - val_accuracy: 0.9888\n",
      "Epoch 12/30\n",
      "7352/7352 [==============================] - 2s 261us/step - loss: 0.0287 - accuracy: 0.9999 - val_loss: 0.0368 - val_accuracy: 0.9983\n",
      "Epoch 13/30\n",
      "7352/7352 [==============================] - 2s 285us/step - loss: 0.0260 - accuracy: 1.0000 - val_loss: 0.0337 - val_accuracy: 0.9973\n",
      "Epoch 14/30\n",
      "7352/7352 [==============================] - 2s 288us/step - loss: 0.0233 - accuracy: 1.0000 - val_loss: 0.0315 - val_accuracy: 0.9976\n",
      "Epoch 15/30\n",
      "7352/7352 [==============================] - 2s 284us/step - loss: 0.0211 - accuracy: 1.0000 - val_loss: 0.0297 - val_accuracy: 0.9976\n",
      "Epoch 16/30\n",
      "7352/7352 [==============================] - 2s 274us/step - loss: 0.0192 - accuracy: 1.0000 - val_loss: 0.0237 - val_accuracy: 0.9990\n",
      "Epoch 17/30\n",
      "7352/7352 [==============================] - 2s 286us/step - loss: 0.0179 - accuracy: 1.0000 - val_loss: 0.0231 - val_accuracy: 0.9980\n",
      "Epoch 18/30\n",
      "7352/7352 [==============================] - 2s 286us/step - loss: 0.0160 - accuracy: 1.0000 - val_loss: 0.0225 - val_accuracy: 0.9980\n",
      "Epoch 19/30\n",
      "7352/7352 [==============================] - 2s 289us/step - loss: 0.0166 - accuracy: 0.9993 - val_loss: 0.0198 - val_accuracy: 0.9983\n",
      "Epoch 20/30\n",
      "7352/7352 [==============================] - 2s 275us/step - loss: 0.0144 - accuracy: 1.0000 - val_loss: 0.0184 - val_accuracy: 0.9983\n",
      "Epoch 21/30\n",
      "7352/7352 [==============================] - 2s 281us/step - loss: 0.0140 - accuracy: 0.9997 - val_loss: 0.0292 - val_accuracy: 0.9952\n",
      "Epoch 22/30\n",
      "7352/7352 [==============================] - 2s 296us/step - loss: 0.0142 - accuracy: 0.9995 - val_loss: 0.0192 - val_accuracy: 0.9983\n",
      "Epoch 23/30\n",
      "7352/7352 [==============================] - 2s 290us/step - loss: 0.0125 - accuracy: 1.0000 - val_loss: 0.0177 - val_accuracy: 0.9986\n",
      "Epoch 24/30\n",
      "7352/7352 [==============================] - 2s 277us/step - loss: 0.0120 - accuracy: 0.9999 - val_loss: 0.0176 - val_accuracy: 0.9983\n",
      "Epoch 25/30\n",
      "7352/7352 [==============================] - 2s 302us/step - loss: 0.0113 - accuracy: 1.0000 - val_loss: 0.0164 - val_accuracy: 0.9983\n",
      "Epoch 26/30\n",
      "7352/7352 [==============================] - 2s 296us/step - loss: 0.0108 - accuracy: 1.0000 - val_loss: 0.0196 - val_accuracy: 0.9976\n",
      "Epoch 27/30\n",
      "7352/7352 [==============================] - 2s 299us/step - loss: 0.0105 - accuracy: 1.0000 - val_loss: 0.0133 - val_accuracy: 0.9993\n",
      "Epoch 28/30\n",
      "7352/7352 [==============================] - 2s 295us/step - loss: 0.0100 - accuracy: 1.0000 - val_loss: 0.0164 - val_accuracy: 0.9983\n",
      "Epoch 29/30\n",
      "7352/7352 [==============================] - 2s 269us/step - loss: 0.0095 - accuracy: 1.0000 - val_loss: 0.0138 - val_accuracy: 0.9986\n",
      "Epoch 30/30\n",
      "7352/7352 [==============================] - 2s 284us/step - loss: 0.0091 - accuracy: 1.0000 - val_loss: 0.0131 - val_accuracy: 0.9986\n",
      "Wall time: 1min 11s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Training the model\n",
    "result = model_bi.fit(X_train_bi,\n",
    "          Y_train_bi,\n",
    "          batch_size=64,\n",
    "          validation_data=(X_test_bi, Y_test_bi),callbacks=[lr,tm],\n",
    "          epochs=30,verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2947/2947 [==============================] - 1s 216us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.01310468845076993, 0.9986426830291748]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_bi.evaluate(X_test_bi,Y_test_bi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred                WALKING  WALKING_UPSTAIRS\n",
      "True                                         \n",
      "LAYING                    0               537\n",
      "SITTING                   2               489\n",
      "STANDING                  2               530\n",
      "WALKING                 496                 0\n",
      "WALKING_DOWNSTAIRS      420                 0\n",
      "WALKING_UPSTAIRS        471                 0\n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "print(confusion_matrix(Y_test, model_bi.predict(X_test_bi)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_bi.save(\"model_bi_class.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_y_new(subset):\n",
    "    \"\"\"\n",
    "    The objective that we are trying to predict is a integer, from 1 to 6,\n",
    "    that represents a human activity. We return a binary representation of \n",
    "    every sample objective as a 6 bits vector using One Hot Encoding\n",
    "    (https://pandas.pydata.org/pandas-docs/stable/generated/pandas.get_dummies.html)\n",
    "    \"\"\"\n",
    "    filename = f'UCI_HAR_Dataset/{subset}/y_{subset}.txt'\n",
    "    y = _read_csv(filename)[0]\n",
    "    label_y = y>3\n",
    "    new_y = y[label_y]\n",
    "    return pd.get_dummies(new_y).as_matrix(),label_y\n",
    "\n",
    "def load_data_new():\n",
    "    \"\"\"\n",
    "    Obtain the dataset from multiple files.\n",
    "    Returns: X_train, X_test, y_train, y_test\n",
    "    \"\"\"\n",
    "    X_train, X_test = load_signals('train'), load_signals('test')\n",
    "    y_train_new, y_label_train = load_y_new('train')\n",
    "    y_val_new,y_label_test = load_y_new('test')\n",
    "    X_train_new = X_train[y_label_train]\n",
    "    X_val_new = X_test[y_label_test]\n",
    "    return X_train_new, X_val_new, y_train_new, y_val_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_st,X_test_st,Y_train_st,Y_test_st  = load_data_new()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_25\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_57 (Conv1D)           (None, 126, 30)           840       \n",
      "_________________________________________________________________\n",
      "batch_normalization_25 (Batc (None, 126, 30)           120       \n",
      "_________________________________________________________________\n",
      "dropout_63 (Dropout)         (None, 126, 30)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_58 (Conv1D)           (None, 124, 50)           4550      \n",
      "_________________________________________________________________\n",
      "batch_normalization_26 (Batc (None, 124, 50)           200       \n",
      "_________________________________________________________________\n",
      "dropout_64 (Dropout)         (None, 124, 50)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_59 (Conv1D)           (None, 122, 100)          15100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_27 (Batc (None, 122, 100)          400       \n",
      "_________________________________________________________________\n",
      "dropout_65 (Dropout)         (None, 122, 100)          0         \n",
      "_________________________________________________________________\n",
      "flatten_25 (Flatten)         (None, 12200)             0         \n",
      "_________________________________________________________________\n",
      "dense_50 (Dense)             (None, 100)               1220100   \n",
      "_________________________________________________________________\n",
      "dropout_66 (Dropout)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_51 (Dense)             (None, 3)                 303       \n",
      "=================================================================\n",
      "Total params: 1,241,613\n",
      "Trainable params: 1,241,253\n",
      "Non-trainable params: 360\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_st= Sequential()\n",
    "model_st.add(Conv1D(30,kernel_size=3,kernel_initializer='glorot_normal',input_shape=(timesteps, input_dim),kernel_regularizer = l2(0.0003),activation ='relu'))\n",
    "model_st.add(BatchNormalization())\n",
    "model_st.add(Dropout(0.7))\n",
    "# model_st.add(MaxPool1D(2))\n",
    "model_st.add(Conv1D(50,kernel_size=3,kernel_initializer='glorot_normal',kernel_regularizer = l2(0.0003),activation ='relu'))\n",
    "model_st.add(BatchNormalization())\n",
    "model_st.add(Dropout(0.4))\n",
    "model_st.add(Conv1D(100,kernel_size=3,kernel_initializer='glorot_normal',kernel_regularizer = l2(0.0003),activation ='relu'))\n",
    "model_st.add(BatchNormalization())\n",
    "model_st.add(Dropout(0.4))\n",
    "#model_st.add(MaxPool1D(2))\n",
    "model_st.add(Flatten())\n",
    "model_st.add(Dense(100,activation = 'relu'))\n",
    "model_st.add(Dropout(0.6))\n",
    "model_st.add(Dense(3,activation = 'softmax'))\n",
    "model_st.summary()\n",
    "# model_st = Sequential()\n",
    "# model_st.add(Conv1D(100,kernel_size=3,kernel_initializer='he_normal',input_shape=(timesteps, input_dim),kernel_regularizer = l2(0.0003),activation ='relu'))\n",
    "# model_st.add(BatchNormalization())\n",
    "# model_st.add(Dropout(0.7))\n",
    "# # model_st.add(MaxPool1D(2))\n",
    "# model_st.add(Conv1D(100,kernel_size=3,kernel_initializer='he_normal',kernel_regularizer = l2(0.0003),activation ='relu'))\n",
    "# model_st.add(BatchNormalization())\n",
    "# model_st.add(Dropout(0.7))\n",
    "# model_st.add(Conv1D(500,kernel_size=3,kernel_initializer='he_normal',kernel_regularizer = l2(0.0003),activation ='relu'))\n",
    "# model_st.add(BatchNormalization())\n",
    "# model_st.add(Dropout(0.7))\n",
    "# #model_st.add(MaxPool1D(2))\n",
    "# model_st.add(Flatten())\n",
    "# model_st.add(Dense(32,activation = 'relu'))\n",
    "# model_st.add(Dropout(0.2))\n",
    "# model_st.add(Dense(3,activation = 'softmax'))\n",
    "# model_st.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 57.8 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model_st.compile(loss='categorical_crossentropy',\n",
    "          optimizer=adam,\n",
    "          metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4067 samples, validate on 1560 samples\n",
      "Epoch 1/30\n",
      "4067/4067 [==============================] - 3s 690us/step - loss: 0.8004 - accuracy: 0.8328 - val_loss: 1.5153 - val_accuracy: 0.5128\n",
      "Epoch 2/30\n",
      "4067/4067 [==============================] - 1s 346us/step - loss: 0.3486 - accuracy: 0.8925 - val_loss: 0.6679 - val_accuracy: 0.5929\n",
      "Epoch 3/30\n",
      "4067/4067 [==============================] - 1s 342us/step - loss: 0.2994 - accuracy: 0.8945 - val_loss: 0.5829 - val_accuracy: 0.7795\n",
      "Epoch 4/30\n",
      "4067/4067 [==============================] - 1s 345us/step - loss: 0.3227 - accuracy: 0.9002 - val_loss: 0.4661 - val_accuracy: 0.8276\n",
      "Epoch 5/30\n",
      "4067/4067 [==============================] - 1s 336us/step - loss: 0.3862 - accuracy: 0.8849 - val_loss: 0.3554 - val_accuracy: 0.8635\n",
      "Epoch 6/30\n",
      "4067/4067 [==============================] - 1s 334us/step - loss: 0.2901 - accuracy: 0.8930 - val_loss: 0.3619 - val_accuracy: 0.8718\n",
      "Epoch 7/30\n",
      "4067/4067 [==============================] - 1s 341us/step - loss: 0.2782 - accuracy: 0.9056 - val_loss: 0.3442 - val_accuracy: 0.8859\n",
      "Epoch 8/30\n",
      "4067/4067 [==============================] - 1s 332us/step - loss: 0.2703 - accuracy: 0.8999 - val_loss: 0.4160 - val_accuracy: 0.8846\n",
      "Epoch 9/30\n",
      "4067/4067 [==============================] - 1s 339us/step - loss: 0.2720 - accuracy: 0.9009 - val_loss: 0.3667 - val_accuracy: 0.8821\n",
      "Epoch 10/30\n",
      "4067/4067 [==============================] - 1s 338us/step - loss: 0.2654 - accuracy: 0.9078 - val_loss: 0.3699 - val_accuracy: 0.8891\n",
      "Epoch 11/30\n",
      "4067/4067 [==============================] - 1s 339us/step - loss: 0.2618 - accuracy: 0.9100 - val_loss: 0.4152 - val_accuracy: 0.8865\n",
      "Epoch 12/30\n",
      "4067/4067 [==============================] - 1s 330us/step - loss: 0.2650 - accuracy: 0.9066 - val_loss: 0.4335 - val_accuracy: 0.8859\n",
      "Epoch 13/30\n",
      "4067/4067 [==============================] - 1s 336us/step - loss: 0.2628 - accuracy: 0.9053 - val_loss: 0.4117 - val_accuracy: 0.8936\n",
      "Epoch 14/30\n",
      "4067/4067 [==============================] - 1s 335us/step - loss: 0.2590 - accuracy: 0.9046 - val_loss: 0.4061 - val_accuracy: 0.8885\n",
      "Epoch 15/30\n",
      "4067/4067 [==============================] - 1s 336us/step - loss: 0.2610 - accuracy: 0.9036 - val_loss: 0.4055 - val_accuracy: 0.8853\n",
      "Epoch 16/30\n",
      "4067/4067 [==============================] - 1s 330us/step - loss: 0.2577 - accuracy: 0.9078 - val_loss: 0.4225 - val_accuracy: 0.8878\n",
      "Epoch 17/30\n",
      "4067/4067 [==============================] - 1s 339us/step - loss: 0.2663 - accuracy: 0.9093 - val_loss: 0.3744 - val_accuracy: 0.8917\n",
      "Epoch 18/30\n",
      "4067/4067 [==============================] - 1s 333us/step - loss: 0.2518 - accuracy: 0.9105 - val_loss: 0.4570 - val_accuracy: 0.8712\n",
      "Epoch 19/30\n",
      "4067/4067 [==============================] - 1s 334us/step - loss: 0.2481 - accuracy: 0.9122 - val_loss: 0.4341 - val_accuracy: 0.8904\n",
      "Epoch 20/30\n",
      "4067/4067 [==============================] - 1s 339us/step - loss: 0.2504 - accuracy: 0.9110 - val_loss: 0.4224 - val_accuracy: 0.8897\n",
      "Epoch 21/30\n",
      "4067/4067 [==============================] - 1s 333us/step - loss: 0.2476 - accuracy: 0.9144 - val_loss: 0.4934 - val_accuracy: 0.8853\n",
      "Epoch 22/30\n",
      "4067/4067 [==============================] - 1s 330us/step - loss: 0.2405 - accuracy: 0.9144 - val_loss: 0.5077 - val_accuracy: 0.8923\n",
      "Epoch 23/30\n",
      "4067/4067 [==============================] - 1s 331us/step - loss: 0.2427 - accuracy: 0.9098 - val_loss: 0.5086 - val_accuracy: 0.8897\n",
      "Epoch 24/30\n",
      "4067/4067 [==============================] - 1s 344us/step - loss: 0.2477 - accuracy: 0.9132 - val_loss: 0.4303 - val_accuracy: 0.8923\n",
      "Epoch 25/30\n",
      "4067/4067 [==============================] - 1s 332us/step - loss: 0.2493 - accuracy: 0.9139 - val_loss: 0.4313 - val_accuracy: 0.8904\n",
      "Epoch 26/30\n",
      "4067/4067 [==============================] - 1s 328us/step - loss: 0.2451 - accuracy: 0.9184 - val_loss: 0.5022 - val_accuracy: 0.8891\n",
      "Epoch 27/30\n",
      "4067/4067 [==============================] - 1s 339us/step - loss: 0.2418 - accuracy: 0.9152 - val_loss: 0.4845 - val_accuracy: 0.8904\n",
      "Epoch 28/30\n",
      "4067/4067 [==============================] - 1s 333us/step - loss: 0.2387 - accuracy: 0.9159 - val_loss: 0.4856 - val_accuracy: 0.8923\n",
      "Epoch 29/30\n",
      "4067/4067 [==============================] - 1s 330us/step - loss: 0.2477 - accuracy: 0.9174 - val_loss: 0.4358 - val_accuracy: 0.8904\n",
      "Epoch 30/30\n",
      "4067/4067 [==============================] - 1s 334us/step - loss: 0.2458 - accuracy: 0.9203 - val_loss: 0.3938 - val_accuracy: 0.8936\n",
      "Wall time: 46.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Training the model\n",
    "result = model_st.fit(X_train_st,\n",
    "          Y_train_st,\n",
    "          batch_size=64,\n",
    "          validation_data=(X_test_st, Y_test_st),callbacks=[lr,tm],\n",
    "          epochs=30,verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1560/1560 [==============================] - 0s 199us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3938026012136386, 0.8935897350311279]"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "#print(confusion_matrix(np.argmax(Y_test_st,axis=1), np.argmax(model_st.predict(X_test_st),axis=1)))\n",
    "model_st.evaluate(X_test_st,Y_test_st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(np.argmax(Y_test_st,axis=1), np.argmax(model_st.predict(X_test_st),axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_st.save(\"model_st_class.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_y_new(subset):\n",
    "    \"\"\"\n",
    "    The objective that we are trying to predict is a integer, from 1 to 6,\n",
    "    that represents a human activity. We return a binary representation of \n",
    "    every sample objective as a 6 bits vector using One Hot Encoding\n",
    "    (https://pandas.pydata.org/pandas-docs/stable/generated/pandas.get_dummies.html)\n",
    "    \"\"\"\n",
    "    filename = f'UCI_HAR_Dataset/{subset}/y_{subset}.txt'\n",
    "    y = _read_csv(filename)[0]\n",
    "    label_y = y<=3\n",
    "    new_y = y[label_y]\n",
    "    return pd.get_dummies(new_y).as_matrix(),label_y\n",
    "\n",
    "def load_data_new():\n",
    "    \"\"\"\n",
    "    Obtain the dataset from multiple files.\n",
    "    Returns: X_train, X_test, y_train, y_test\n",
    "    \"\"\"\n",
    "    X_train, X_test = load_signals('train'), load_signals('test')\n",
    "    y_train_new, y_label_train = load_y_new('train')\n",
    "    y_val_new,y_label_test = load_y_new('test')\n",
    "    X_train_new = X_train[y_label_train]\n",
    "    X_val_new = X_test[y_label_test]\n",
    "    return X_train_new, X_val_new, y_train_new, y_val_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\patha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:12: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "X_train_dy,X_test_dy,Y_train_dy,Y_test_dy  = load_data_new()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_37 (Conv1D)           (None, 124, 64)           2944      \n",
      "_________________________________________________________________\n",
      "conv1d_38 (Conv1D)           (None, 120, 32)           10272     \n",
      "_________________________________________________________________\n",
      "dropout_39 (Dropout)         (None, 120, 32)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_13 (MaxPooling (None, 60, 32)            0         \n",
      "_________________________________________________________________\n",
      "flatten_17 (Flatten)         (None, 1920)              0         \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 16)                30736     \n",
      "_________________________________________________________________\n",
      "dropout_40 (Dropout)         (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 3)                 51        \n",
      "=================================================================\n",
      "Total params: 44,003\n",
      "Trainable params: 44,003\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_dy= Sequential()\n",
    "model_dy.add(Conv1D(64,kernel_size=5,kernel_initializer='glorot_normal',input_shape=(timesteps, input_dim),kernel_regularizer = l2(0.0003),activation ='relu'))\n",
    "#model_dy.add(BatchNormalization())\n",
    "#model_dy.add(MaxPool1D(2))\n",
    "model_dy.add(Conv1D(32,kernel_size=5,kernel_initializer='glorot_normal',kernel_regularizer = l2(0.0003),activation ='relu'))\n",
    "#model_dy.add(BatchNormalization())\n",
    "model_dy.add(Dropout(0.7))\n",
    "# model_dy.add(Conv1D(32,kernel_size=7,kernel_initializer='he_normal',kernel_regularizer = l2(0.003),activation ='relu'))\n",
    "# #model_dy.add(BatchNormalization())\n",
    "# model_dy.add(Dropout(0.6))\n",
    "model_dy.add(MaxPool1D(2))\n",
    "model_dy.add(Flatten())\n",
    "model_dy.add(Dense(16,activation = 'relu'))\n",
    "model_dy.add(Dropout(0.2))\n",
    "model_dy.add(Dense(3,activation = 'softmax'))\n",
    "model_dy.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 122 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model_dy.compile(loss='categorical_crossentropy',\n",
    "          optimizer=adam,\n",
    "          metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3285 samples, validate on 1387 samples\n",
      "Epoch 1/30\n",
      "3285/3285 [==============================] - 1s 439us/step - loss: 0.6504 - accuracy: 0.7233 - val_loss: 0.5196 - val_accuracy: 0.8558\n",
      "Epoch 2/30\n",
      "3285/3285 [==============================] - 1s 216us/step - loss: 0.1447 - accuracy: 0.9589 - val_loss: 0.2770 - val_accuracy: 0.9387\n",
      "Epoch 3/30\n",
      "3285/3285 [==============================] - 1s 201us/step - loss: 0.0706 - accuracy: 0.9854 - val_loss: 0.3495 - val_accuracy: 0.9315\n",
      "Epoch 4/30\n",
      "3285/3285 [==============================] - 1s 196us/step - loss: 0.0435 - accuracy: 0.9942 - val_loss: 0.3510 - val_accuracy: 0.9481\n",
      "Epoch 5/30\n",
      "3285/3285 [==============================] - 1s 195us/step - loss: 0.0377 - accuracy: 0.9957 - val_loss: 0.2735 - val_accuracy: 0.9618\n",
      "Epoch 6/30\n",
      "3285/3285 [==============================] - 1s 160us/step - loss: 0.0324 - accuracy: 0.9970 - val_loss: 0.3314 - val_accuracy: 0.9531\n",
      "Epoch 7/30\n",
      "3285/3285 [==============================] - 1s 163us/step - loss: 0.0315 - accuracy: 0.9963 - val_loss: 0.2419 - val_accuracy: 0.9567\n",
      "Epoch 8/30\n",
      "3285/3285 [==============================] - 1s 161us/step - loss: 0.0253 - accuracy: 0.9985 - val_loss: 0.3123 - val_accuracy: 0.9589\n",
      "Epoch 9/30\n",
      "3285/3285 [==============================] - 1s 168us/step - loss: 0.0354 - accuracy: 0.9951 - val_loss: 0.2665 - val_accuracy: 0.9603\n",
      "Epoch 10/30\n",
      "3285/3285 [==============================] - 1s 170us/step - loss: 0.0264 - accuracy: 0.9976 - val_loss: 0.2918 - val_accuracy: 0.9452\n",
      "Epoch 11/30\n",
      "3285/3285 [==============================] - 1s 169us/step - loss: 0.0253 - accuracy: 0.9979 - val_loss: 0.2884 - val_accuracy: 0.9632\n",
      "Epoch 12/30\n",
      "3285/3285 [==============================] - 1s 168us/step - loss: 0.0261 - accuracy: 0.9985 - val_loss: 0.2508 - val_accuracy: 0.9553\n",
      "Epoch 13/30\n",
      "3285/3285 [==============================] - 1s 170us/step - loss: 0.0230 - accuracy: 0.9994 - val_loss: 0.2899 - val_accuracy: 0.9618\n",
      "Epoch 14/30\n",
      "3285/3285 [==============================] - 1s 171us/step - loss: 0.0234 - accuracy: 0.9976 - val_loss: 0.2945 - val_accuracy: 0.9611\n",
      "Epoch 15/30\n",
      "3285/3285 [==============================] - 1s 162us/step - loss: 0.0218 - accuracy: 0.9991 - val_loss: 0.3251 - val_accuracy: 0.9611\n",
      "Epoch 16/30\n",
      "3285/3285 [==============================] - 1s 160us/step - loss: 0.0201 - accuracy: 1.0000 - val_loss: 0.3274 - val_accuracy: 0.9611\n",
      "Epoch 17/30\n",
      "3285/3285 [==============================] - 1s 169us/step - loss: 0.0211 - accuracy: 0.9991 - val_loss: 0.3114 - val_accuracy: 0.9611\n",
      "Epoch 18/30\n",
      "3285/3285 [==============================] - 1s 158us/step - loss: 0.0204 - accuracy: 0.9994 - val_loss: 0.2790 - val_accuracy: 0.9611\n",
      "Epoch 19/30\n",
      "3285/3285 [==============================] - 1s 173us/step - loss: 0.0210 - accuracy: 0.9991 - val_loss: 0.3069 - val_accuracy: 0.9632\n",
      "Epoch 20/30\n",
      "3285/3285 [==============================] - 1s 172us/step - loss: 0.0194 - accuracy: 0.9994 - val_loss: 0.3064 - val_accuracy: 0.9618\n",
      "Epoch 21/30\n",
      "3285/3285 [==============================] - 1s 162us/step - loss: 0.0197 - accuracy: 0.9994 - val_loss: 0.3333 - val_accuracy: 0.9603\n",
      "Epoch 22/30\n",
      "3285/3285 [==============================] - 1s 177us/step - loss: 0.0189 - accuracy: 0.9994 - val_loss: 0.3040 - val_accuracy: 0.9611\n",
      "Epoch 23/30\n",
      "3285/3285 [==============================] - 1s 174us/step - loss: 0.0201 - accuracy: 0.9988 - val_loss: 0.3651 - val_accuracy: 0.9553\n",
      "Epoch 24/30\n",
      "3285/3285 [==============================] - 1s 174us/step - loss: 0.0227 - accuracy: 0.9976 - val_loss: 0.2609 - val_accuracy: 0.9582\n",
      "Epoch 25/30\n",
      "3285/3285 [==============================] - 1s 162us/step - loss: 0.0187 - accuracy: 0.9997 - val_loss: 0.3188 - val_accuracy: 0.9603\n",
      "Epoch 26/30\n",
      "3285/3285 [==============================] - 1s 171us/step - loss: 0.0180 - accuracy: 0.9997 - val_loss: 0.2902 - val_accuracy: 0.9618\n",
      "Epoch 27/30\n",
      "3285/3285 [==============================] - 1s 164us/step - loss: 0.0191 - accuracy: 0.9991 - val_loss: 0.3629 - val_accuracy: 0.9603\n",
      "Epoch 28/30\n",
      "3285/3285 [==============================] - 1s 168us/step - loss: 0.0180 - accuracy: 0.9997 - val_loss: 0.3207 - val_accuracy: 0.9625\n",
      "Epoch 29/30\n",
      "3285/3285 [==============================] - 1s 194us/step - loss: 0.0190 - accuracy: 0.9991 - val_loss: 0.3451 - val_accuracy: 0.9589\n",
      "Epoch 30/30\n",
      "3285/3285 [==============================] - 1s 200us/step - loss: 0.0182 - accuracy: 0.9985 - val_loss: 0.3329 - val_accuracy: 0.9611\n",
      "Wall time: 20.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Training the model\n",
    "result = model_dy.fit(X_train_dy,\n",
    "          Y_train_dy,\n",
    "          batch_size=64,\n",
    "          validation_data=(X_test_dy, Y_test_dy),callbacks=[lr,tm],\n",
    "          epochs=30,verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1387/1387 [==============================] - 0s 128us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.13676273131712186, 0.9769286513328552]"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "#print(confusion_matrix(Y_test_dy, model_dy.predict(X_test_dy)))\n",
    "model_dy.evaluate(X_test_dy,Y_test_dy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dy.save(\"model_dy_class.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dy.load_weights(\"model_dy_class.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sharpening Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sharpen(x_test, sigma, alpha):\n",
    "    d = x_test.shape[0]\n",
    "    r = x_test.shape[1]\n",
    "    c = x_test.shape[2]\n",
    "    container = np.empty((d,r, c))\n",
    "    i = 0\n",
    "\n",
    "    for row in x_test:\n",
    "        test = row\n",
    "        blurred = ndimage.gaussian_filter(test, sigma)\n",
    "        sharpened = test + alpha * (test - blurred)\n",
    "        container[i] = sharpened\n",
    "        i = i + 1\n",
    "    return container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import ndimage\n",
    "alpha = np.arange(0.05, 2.55, 0.05)\n",
    "sigma = np.arange(5, 10, 1)\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix\n",
    "def display_output(X_test,Y_test):\n",
    "    accuracy=[]\n",
    "    for s in sigma:\n",
    "        for a in alpha:\n",
    "            # Sharpen test data with various sigma (for Gaussian filter) and alpha value combinations\n",
    "            X_test_sharpen = sharpen(X_test, s, a)\n",
    "            pred_dyna_sharpen = model_dy.predict(X_test_sharpen)\n",
    "            accuracy.append(accuracy_score(Y_test, np.argmax(pred_dyna_sharpen, axis=1)))\n",
    "    return(accuracy)\n",
    "            #print(\">>> sigma={}, alpha={:.2f}\".format(s, a))\n",
    "#             print(accuracy_score(np.argmax(Y_test,axis=1), np.argmax(pred_dyna_sharpen, axis=1)))\n",
    "#             print(confusion_matrix(np.argmax(Y_test,axis=1), np.argmax(pred_dyna_sharpen, axis=1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function to read the data from csv file\n",
    "def _read_csv(filename):\n",
    "    return pd.read_csv(filename, delim_whitespace=True, header=None)\n",
    "\n",
    "# Utility function to load the load\n",
    "def load_signals(subset):\n",
    "    signals_data = []\n",
    "\n",
    "    for signal in SIGNALS:\n",
    "        filename = f'UCI_HAR_Dataset/{subset}/Inertial Signals/{signal}_{subset}.txt'\n",
    "        signals_data.append(\n",
    "            _read_csv(filename).as_matrix()\n",
    "        ) \n",
    "\n",
    "    return np.transpose(signals_data, (1, 2, 0))\n",
    "\n",
    "def load_y(subset):\n",
    "    \"\"\"\n",
    "    The objective that we are trying to predict is a integer, from 1 to 6,\n",
    "    that represents a human activity. We return a binary representation of \n",
    "    every sample objective as a 6 bits vector using One Hot Encoding\n",
    "    (https://pandas.pydata.org/pandas-docs/stable/generated/pandas.get_dummies.html)\n",
    "    \"\"\"\n",
    "    filename = f'UCI_HAR_Dataset/{subset}/y_{subset}.txt'\n",
    "    y = _read_csv(filename)[0]\n",
    "\n",
    "    return pd.get_dummies(y).as_matrix()\n",
    "def load_data():\n",
    "    \"\"\"\n",
    "    Obtain the dataset from multiple files.\n",
    "    Returns: X_train, X_test, y_train, y_test\n",
    "    \"\"\"\n",
    "    X_train, X_test = load_signals('train'), load_signals('test')\n",
    "    y_train, y_test = load_y('train'), load_y('test')\n",
    "\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X train shape : (7352, 128, 9)\n",
      "X test shape : (2947, 128, 9)\n",
      "Y train shape : (7352, 6)\n",
      "Y train shape : (2947, 6)\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "X_train, X_test, Y_train, Y_test = load_data()\n",
    "print(\"X train shape :\",X_train.shape)\n",
    "print(\"X test shape :\",X_test.shape)\n",
    "print(\"Y train shape :\",Y_train.shape)\n",
    "print(\"Y train shape :\",Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification of Sitting and Laying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_st_sitlay = X_train_st[np.argmax(Y_train_st,axis=1)!=1]\n",
    "X_test_st_sitlay = X_test_st[np.argmax(Y_test_st,axis=1)!=1]\n",
    "Y_train_st_sitlay = Y_train_st[np.argmax(Y_train_st,axis=1)!=1]\n",
    "Y_test_st_sitlay = Y_test_st[np.argmax(Y_test_st,axis=1)!=1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_39 (Conv1D)           (None, 124, 64)           2944      \n",
      "_________________________________________________________________\n",
      "conv1d_40 (Conv1D)           (None, 120, 32)           10272     \n",
      "_________________________________________________________________\n",
      "dropout_41 (Dropout)         (None, 120, 32)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_14 (MaxPooling (None, 60, 32)            0         \n",
      "_________________________________________________________________\n",
      "flatten_18 (Flatten)         (None, 1920)              0         \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 16)                30736     \n",
      "_________________________________________________________________\n",
      "dropout_42 (Dropout)         (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 3)                 51        \n",
      "=================================================================\n",
      "Total params: 44,003\n",
      "Trainable params: 44,003\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_st_bi= Sequential()\n",
    "model_st_bi.add(Conv1D(64,kernel_size=5,kernel_initializer='glorot_normal',input_shape=(timesteps, input_dim),kernel_regularizer = l2(0.0003),activation ='relu'))\n",
    "#model_st_bi.add(BatchNormalization())\n",
    "#model_st_bi.add(MaxPool1D(2))\n",
    "model_st_bi.add(Conv1D(32,kernel_size=5,kernel_initializer='glorot_normal',kernel_regularizer = l2(0.0003),activation ='relu'))\n",
    "#model_st_bi.add(BatchNormalization())\n",
    "model_st_bi.add(Dropout(0.7))\n",
    "# model_st_bi.add(Conv1D(32,kernel_size=7,kernel_initializer='he_normal',kernel_regularizer = l2(0.003),activation ='relu'))\n",
    "# #model_st_bi.add(BatchNormalization())\n",
    "# model_st_bi.add(Dropout(0.6))\n",
    "model_st_bi.add(MaxPool1D(2))\n",
    "model_st_bi.add(Flatten())\n",
    "model_st_bi.add(Dense(16,activation = 'relu'))\n",
    "model_st_bi.add(Dropout(0.3))\n",
    "model_st_bi.add(Dense(3,activation = 'softmax'))\n",
    "model_st_bi.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 40.9 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model_st_bi.compile(loss='categorical_crossentropy',\n",
    "          optimizer=adam,\n",
    "          metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2693 samples, validate on 1028 samples\n",
      "Epoch 1/30\n",
      "2693/2693 [==============================] - 2s 616us/step - loss: 0.1667 - accuracy: 0.9577 - val_loss: 0.0167 - val_accuracy: 1.0000\n",
      "Epoch 2/30\n",
      "2693/2693 [==============================] - 0s 161us/step - loss: 0.0235 - accuracy: 0.9978 - val_loss: 0.0149 - val_accuracy: 1.0000\n",
      "Epoch 3/30\n",
      "2693/2693 [==============================] - 0s 173us/step - loss: 0.0161 - accuracy: 0.9996 - val_loss: 0.0134 - val_accuracy: 1.0000\n",
      "Epoch 4/30\n",
      "2693/2693 [==============================] - 0s 169us/step - loss: 0.0141 - accuracy: 1.0000 - val_loss: 0.0123 - val_accuracy: 1.0000\n",
      "Epoch 5/30\n",
      "2693/2693 [==============================] - 0s 168us/step - loss: 0.0134 - accuracy: 1.0000 - val_loss: 0.0114 - val_accuracy: 1.0000\n",
      "Epoch 6/30\n",
      "2693/2693 [==============================] - 0s 169us/step - loss: 0.0114 - accuracy: 1.0000 - val_loss: 0.0108 - val_accuracy: 1.0000\n",
      "Epoch 7/30\n",
      "2693/2693 [==============================] - 0s 163us/step - loss: 0.0112 - accuracy: 0.9996 - val_loss: 0.0102 - val_accuracy: 1.0000\n",
      "Epoch 8/30\n",
      "2693/2693 [==============================] - 0s 168us/step - loss: 0.0105 - accuracy: 1.0000 - val_loss: 0.0097 - val_accuracy: 1.0000\n",
      "Epoch 9/30\n",
      "2693/2693 [==============================] - 0s 169us/step - loss: 0.0105 - accuracy: 0.9996 - val_loss: 0.0093 - val_accuracy: 1.0000\n",
      "Epoch 10/30\n",
      "2693/2693 [==============================] - 0s 167us/step - loss: 0.0102 - accuracy: 0.9993 - val_loss: 0.0091 - val_accuracy: 1.0000\n",
      "Epoch 11/30\n",
      "2693/2693 [==============================] - 1s 221us/step - loss: 0.0108 - accuracy: 0.9989 - val_loss: 0.0088 - val_accuracy: 1.0000\n",
      "Epoch 12/30\n",
      "2693/2693 [==============================] - 0s 173us/step - loss: 0.0105 - accuracy: 0.9996 - val_loss: 0.0086 - val_accuracy: 1.0000\n",
      "Epoch 13/30\n",
      "2693/2693 [==============================] - 0s 173us/step - loss: 0.0095 - accuracy: 0.9993 - val_loss: 0.0085 - val_accuracy: 1.0000\n",
      "Epoch 14/30\n",
      "2693/2693 [==============================] - 0s 164us/step - loss: 0.0094 - accuracy: 0.9989 - val_loss: 0.0083 - val_accuracy: 1.0000\n",
      "Epoch 15/30\n",
      "2693/2693 [==============================] - 0s 165us/step - loss: 0.0091 - accuracy: 0.9989 - val_loss: 0.0081 - val_accuracy: 1.0000\n",
      "Epoch 16/30\n",
      "2693/2693 [==============================] - 0s 162us/step - loss: 0.0096 - accuracy: 0.9996 - val_loss: 0.0079 - val_accuracy: 1.0000\n",
      "Epoch 17/30\n",
      "2693/2693 [==============================] - 0s 157us/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 0.0078 - val_accuracy: 1.0000\n",
      "Epoch 18/30\n",
      "2693/2693 [==============================] - 0s 170us/step - loss: 0.0085 - accuracy: 0.9996 - val_loss: 0.0076 - val_accuracy: 1.0000\n",
      "Epoch 19/30\n",
      "2693/2693 [==============================] - 0s 185us/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 0.0075 - val_accuracy: 1.0000\n",
      "Epoch 20/30\n",
      "2693/2693 [==============================] - 1s 212us/step - loss: 0.0078 - accuracy: 0.9996 - val_loss: 0.0074 - val_accuracy: 1.0000\n",
      "Epoch 21/30\n",
      "2693/2693 [==============================] - 1s 186us/step - loss: 0.0083 - accuracy: 0.9996 - val_loss: 0.0073 - val_accuracy: 1.0000\n",
      "Epoch 22/30\n",
      "2693/2693 [==============================] - 0s 179us/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 0.0072 - val_accuracy: 1.0000\n",
      "Epoch 23/30\n",
      "2693/2693 [==============================] - 1s 203us/step - loss: 0.0093 - accuracy: 0.9985 - val_loss: 0.0071 - val_accuracy: 1.0000\n",
      "Epoch 24/30\n",
      "2693/2693 [==============================] - 1s 221us/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 0.0070 - val_accuracy: 1.0000\n",
      "Epoch 25/30\n",
      "2693/2693 [==============================] - 0s 180us/step - loss: 0.0089 - accuracy: 0.9993 - val_loss: 0.0070 - val_accuracy: 1.0000\n",
      "Epoch 26/30\n",
      "2693/2693 [==============================] - 0s 163us/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 0.0069 - val_accuracy: 1.0000\n",
      "Epoch 27/30\n",
      "2693/2693 [==============================] - 0s 168us/step - loss: 0.0085 - accuracy: 0.9993 - val_loss: 0.0068 - val_accuracy: 1.0000\n",
      "Epoch 28/30\n",
      "2693/2693 [==============================] - 0s 175us/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 0.0067 - val_accuracy: 1.0000\n",
      "Epoch 29/30\n",
      "2693/2693 [==============================] - 0s 160us/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 0.0066 - val_accuracy: 1.0000\n",
      "Epoch 30/30\n",
      "2693/2693 [==============================] - 0s 161us/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 0.0066 - val_accuracy: 1.0000\n",
      "Wall time: 17.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Training the model\n",
    "result = model_st_bi.fit(X_train_st_sitlay,\n",
    "          Y_train_st_sitlay,\n",
    "          batch_size=64,\n",
    "          validation_data=(X_test_st_sitlay, Y_test_st_sitlay),callbacks=[lr,tm],\n",
    "          epochs=30,verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[491   0]\n",
      " [  0 537]]\n",
      "1028/1028 [==============================] - 0s 125us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.00658893180061639, 1.0]"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(confusion_matrix(np.argmax(Y_test_st_sitlay,axis=1), np.argmax(model_st_bi.predict(X_test_st_sitlay),axis=1)))\n",
    "model_st_bi.evaluate(X_test_st_sitlay,Y_test_st_sitlay)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best Sigma and alpha for Test Sharpening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy=[]\n",
    "alpha = np.arange(0.05, 2.55, 0.05)\n",
    "sigma = np.arange(0, 5, 0.5) \n",
    "for s in sigma:\n",
    "    for a in alpha:\n",
    "        X_test_st_ = sharpen(X_test_st_,s,a)\n",
    "        X_test_dy_ = sharpen(X_test_dy_,s,a)\n",
    "        y_pred_st = model_st.predict_classes(X_test_st_)+3\n",
    "        y_pred_dy = model_dy.predict_classes(X_test_dy_)\n",
    "        total_y = np.concatenate([y_pred_st,y_pred_dy])\n",
    "        accuracy.append(accuracy_score(np.argmax(y_test,axis=1),total_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacking the models for Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_bi = model_bi.predict_classes(X_test_bi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_st_= X_test[y_pred_bi>0]   # Static class\n",
    "X_test_dy_ = X_test[y_pred_bi<1]  # Dynamic Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test_st_ = Y_test[y_pred_bi>0]\n",
    "Y_test_dy_ = Y_test[y_pred_bi<1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = np.concatenate([Y_test_st_,Y_test_dy_]) #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sharpening of Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_st_ = sharpen(X_test_st_,5,0.05)\n",
    "X_test_dy_ = sharpen(X_test_dy_,5,0.05)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_st = model_st.predict_classes(X_test_st_)+3\n",
    "y_pred_dy = model_dy.predict_classes(X_test_dy_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_y = np.concatenate([y_pred_st,y_pred_dy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Using Divide and Conquer Method-> 0.9424377332880896\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy Using Divide and Conquer Method->\",accuracy_score(np.argmax(y_test,axis=1),total_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2000806e5f8>"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.heatmap(confusion_matrix(np.argmax(y_test,axis=1),total_y),annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------+----------+--------+\n",
      "|         Model         | Accuracy |  loss  |\n",
      "+-----------------------+----------+--------+\n",
      "|  LSTM with one Layer  |  90.97   | 0.3087 |\n",
      "|  LSTM with two Layer  |  91.78   | 0.3971 |\n",
      "| LSTM with three Layer |  89.51   | 0.4863 |\n",
      "| Divide-Conquer Method |  94.24   | 0.2042 |\n",
      "+-----------------------+----------+--------+\n"
     ]
    }
   ],
   "source": [
    "from prettytable import PrettyTable\n",
    "x = PrettyTable()\n",
    "x.field_names = [\"Model\",\"Accuracy\",\"loss\"]\n",
    "x.add_row([\"LSTM with one Layer\",90.97,0.3087])\n",
    "x.add_row([\"LSTM with two Layer\",91.78,0.3971])\n",
    "x.add_row([\"LSTM with three Layer\",89.51,0.4863])\n",
    "x.add_row([\"Divide-Conquer Method\",94.24,0.2042])\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. All three model is getting confused between standing and sitting, after running so many code at last I got 91.8% accuracy in LSTM with 2 layers.\n",
    "2. Some code gives nan as my losses and get stuck in same accuracy of 16.83% for many epochs ."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
